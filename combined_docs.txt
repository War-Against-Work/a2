===============================================
HYBRID ARCHITECTURE OVERVIEW
===============================================

- --
title: "Hybrid Architecture Overview"
type: design
status: active
created: "2024-01-01"
updated: "2024-01-01"
- --

# A2 Robot: Hybrid Cloud-Local System Architecture Overview

## Overview

This document provides detailed information and implementation guidance.

> **Document Status:** CURRENT
> **Last Updated:** 2025-05-28
> **Version:** 1.0.0
> **Scope:** Phase 1

## Table of Contents

- [Overview](#overview)
- [1. Purpose and Vision](#1-purpose-and-vision)
  - [1.1. Phase 1 Implementation Focus](#1-1-phase-1-implementation-focus)
- [2. Architectural Tiers Overview](#2-architectural-tiers-overview)
  - [2.1. Onboard (Local) Tier](#2-1-onboard-local-tier)
  - [2.2. Cloud (Remote) Tier](#2-2-cloud-remote-tier)
- [3. Key Components and Responsibilities](#3-key-components-and-responsibilities)
  - [3.1. Onboard Tier Components](#3-1-onboard-tier-components)
    - [3.1.1. Ultra-Fast Safety Layer (P0 - Teensy 4.1)](#3-1-1-ultra-fast-safety-layer-p0-teensy-4-1)
    - [3.1.2. Fast Path Reflex & Control Layer (P1 - Raspberry Pi 5)](#3-1-2-fast-path-reflex-control-layer-p1-raspberry-pi-5)
    - [3.1.3. Local Perception & Interface Layer (NVIDIA RTX 4080 system - Local)](#3-1-3-local-perception-interface-layer-nvidia-rtx-4080-local)
    - [3.1.4. Cloud Gateway Node (Raspberry Pi 5)](#3-1-4-cloud-gateway-node-raspberry-pi-5)
  - [3.3. Local Development Mode](#3-3-local-development-mode)
    - [3.3.1. Local Mistral 7B Deployment](#3-3-1-local-mistral-7b-deployment)
    - [3.3.2. Direct ROS 2 Humble Integration for LLMs](#3-3-2-direct-ros-2-integration-for-llms)
    - [3.3.3. Config-Based Cloud/Local Switching](#3-3-3-config-based-cloud-local-switching)
    - [3.3.4. Local Development Benefits](#3-3-4-local-development-benefits)
  - [3.2. Cloud Tier Components (RunPod or similar)](#3-2-cloud-tier-components-runpod-or-similar)
    - [3.2.1. Multi-Large Language Model (LLM) Swarm (Containerized Services)](#3-2-1-multi-llm-swarm-containerized-services)
    - [3.2.2. Conversational Speech Model (Conversational Speech Model (CSM) - Containerized Service)](#3-2-2-conversational-speech-model-csm-containerized-service)
    - [3.2.3. Master Shared State System (Master Shared State System (MSSS) - Cloud)](#3-2-3-master-shared-state-system-msss-cloud)
- [4. Data Flow and Communication Strategy](#4-data-flow-and-communication-strategy)
  - [4.1. Onboard Data Loops](#4-1-onboard-data-loops)
  - [4.2. Hybrid Local-Cloud Interaction Loop (Simplified for Phase 1)](#4-2-hybrid-local-cloud-interaction-loop-simplified-for-phase-1)
  - [4.3. Inter-Cloud Communication](#4-3-inter-cloud-communication)
  - [4.4. WebSocket State Streaming](#4-4-websocket-state-streaming)
    - [4.4.1. Event-Driven State Updates](#4-4-1-event-driven-state-updates)
    - [4.4.2. Local State Prediction During Network Latency](#4-4-2-local-state-prediction-during-network-latency)
    - [4.4.3. Connection Management](#4-4-3-connection-management)
    - [4.4.4. Performance Benefits](#4-4-4-performance-benefits)
- [5. Latency Management and Responsiveness](#5-latency-management-and-responsiveness)
- [6. Benefits of Hybrid Architecture (Reiteration)](#6-benefits-of-hybrid-architecture-reiteration)
  - [6.1. Expression-Driven Latency Targets](#6-1-expression-driven-latency-targets)
    - [6.1.1. Reflex Responses: <75ms (Unchanged)](#6-1-1-reflex-responses-75ms-unchanged)
    - [6.1.2. Speech Onset to Motion: <200ms](#6-1-2-speech-onset-to-motion-200ms)
    - [6.1.3. Full Interaction Loop: 2.5-4s Acceptable Range](#6-1-3-full-interaction-loop-2-5-4s-acceptable-range)
    - [6.1.4. Expression Quality vs Latency Trade-offs](#6-1-4-expression-quality-vs-latency-trade-offs)
    - [6.1.5. Context-Aware Latency Adaptation](#6-1-5-context-aware-latency-adaptation)
- [7. Evolution Beyond Phase 1](#7-evolution-beyond-phase-1)

- --

## 1. Purpose and Vision

This document outlines the hybrid cloud-local system architecture for the A2 Robotic Assistant. The primary goal is to enable complex, intelligent, and expressive robotic behavior by strategically combining onboard processing for real-time tasks with cloud computing for resource-intensive AI computations. This architecture is designed for responsive interaction, sophisticated reasoning using Large Language Models (LLMs), and natural-sounding custom Text-to-Speech (Text-to-Speech (TTS)), while providing a clear path for future scalability, modularity, and feature expansion (such as limbs).

The vision is a robotic platform where:
-   **Local processing** (onboard the robot) handles immediate safety, physical reflexes, direct hardware control, and time-sensitive perception tasks.
-   **Cloud processing** (e.g., hosted on RunPod) provides the advanced cognitive functions, including a Multi-Large Language Model (LLM) Swarm for reasoning and dialogue, and a Conversational Speech Model (Conversational Speech Model (CSM)) for high-fidelity Text-to-Speech (TTS).
-   Communication between local and cloud tiers is optimized for interactive responsiveness, with particular attention to minimizing perceived latency for speech and reactions.

### 1.1. Phase 1 Implementation Focus

This architecture will be implemented in phases. **Phase 1 (Essential Core)**, as detailed in `a2_phase_1_implementation_priorities.md`, focuses on establishing the foundational hybrid pipeline with key simplifications to achieve core functionality rapidly. This includes:
-   Basic safety layers (P0, P1) and a simplified Execution Router.
-   A functional, albeit simplified, cloud bridge (Cloud Gateway) using polling.
-   Deployment of simplified or mock versions of the cloud Large Language Model (LLM) Swarm and Conversational Speech Model (CSM) Text-to-Speech (TTS).
-   A simplified Master Shared State System (Master Shared State System (MSSS)) with basic conflict resolution.
-   The primary goal of Phase 1 is to validate the end-to-end flow, test core technologies (Mistral 7B LoRAs, Conversational Speech Model (CSM) voice cloning), and achieve basic embodied spoken interaction. Subsequent phases will build out the more advanced features and resilience mechanisms described herein.

## 2. Architectural Tiers Overview

The A2 system is structured into two primary operational tiers, interconnected via a network communication layer managed by the Cloud Gateway.

### 2.1. Onboard (Local) Tier

Resides directly on the A2 robot's physical hardware. It is responsible for all real-time operations and direct interaction with the physical world.
-   **Key Responsibilities:** Ultra-fast safety, fast path reflexes, direct actuator control, low-latency sensor data acquisition and some processing, local state caching, execution of commands, and managing communication with cloud services.
-   **Key Hardware:**
    -   **Teensy 4.1:** For the Ultra-Fast Safety Layer (P0) and real-time I/O.
    -   **Raspberry Pi 5:** Hosts the Fast Path Reflex System (P1), Execution Router, Local Shared State Cache (Local Shared State Cache (LSSC)), Cloud Gateway node, and serves as the primary ROS 2 Humble hub.
    -   **NVIDIA RTX 4080 system (Local Host PC/System):** Dedicated to local GPU-accelerated tasks like computer vision (e.g., YOLO), potentially local Speech-to-Text (Speech-to-Text (STT)), and a telemetry web interface.

### 2.2. Cloud (Remote) Tier

Hosted on a cloud computing platform (e.g., RunPod). This tier handles the computationally demanding AI and cognitive functions.
-   **Key Responsibilities:** Advanced reasoning, dialogue management, complex motion planning, high-fidelity Text-to-Speech (TTS) generation, and hosting the master version of the system's shared state.
-   **Key Services (Containerized):**
    -   **Multi-Large Language Model (LLM) Swarm:** Specialized LLMs (e.g., Mistral 7B base + LoRAs) for Communication, Decision-making, and Motion planning.
    -   **Conversational Speech Model (Conversational Speech Model (CSM)):** Advanced Text-to-Speech (TTS) engine (e.g., based on LLaMA 3.2-1B) with custom voice cloning and audio streaming.
    -   **Master Shared State System (Master Shared State System (MSSS)):** Central Redis-backed database for system-wide state, inter-Large Language Model (LLM) coordination, and cloud-side conflict resolution.

## 3. Key Components and Responsibilities

### 3.1. Onboard Tier Components

#### 3.1.1. Ultra-Fast Safety Layer (P0 - Teensy 4.1)
-   **Implementation:** Firmware on Teensy 4.1 (`a2_teensy_firmware_design.md`).
-   **Loop Rate:** ~1 kHz.
-   **Responsibilities:** Hardware-level safety (E-Stop, motor current monitoring if feasible), actuator feedback processing, Inertial Measurement Unit (IMU) data acquisition. Can directly influence motor enable lines for immediate P0 stops.

#### 3.1.2. Fast Path Reflex & Control Layer (P1 - Raspberry Pi 5)
-   **Implementation:** ROS 2 Humble nodes (`a2_local_fast_path_reflex_system.md`, `a2_execution_router_onboard_design.md`, `a2_onboard_hardware_interfaces.md`, `a2_local_sensor_processing.md`).
-   **Loop Rate:** ~10-100 Hz.
-   **Responsibilities:**
    -   **Local Sensor Processing:** Fusion (e.g., EKF for pose), basic obstacle detection from depth, audio event detection.
    -   **Fast Path Reflex System (Fast Path Reflex System (FPRS)):** Generates P1 priority motion commands based on local sensor data (e.g., proximal object avoidance, loud noise orienting).
    -   **Execution Router:** Arbitrates commands from P0 (Teensy 4.1), P1 (Fast Path Reflex System (FPRS)), and P2/P3 (cloud via Local Shared State Cache (LSSC)). Translates abstract commands into hardware-specific signals. Enforces local constraints.
    -   **Hardware Interface Layer (Hardware Interface Layer (HIL)):** Nodes for Teensy 4.1 Universal Asynchronous Receiver-Transmitter (UART) communication, Dynamixel control, L16 motor driver (BTS7960) control.
    -   **Local Shared State Cache (Local Shared State Cache (LSSC)):** (`a2_local_shared_state_cache_design.md`) In-memory cache of local state and directives from the cloud.

#### 3.1.3. Local Perception & Interface Layer (NVIDIA RTX 4080 system - Local)
-   **Implementation:** ROS 2 Humble nodes, Docker containers (`a2_local_rtx4080_services.md`).
-   **Responsibilities:**
    -   **Advanced Computer Vision:** Object detection (YOLO), human pose estimation, visual gesture recognition.
    -   **Local Speech-to-Text (Speech-to-Text (STT) - Phase 1 Target):** GPU-accelerated Whisper (small/medium) for transcribing user speech.
    -   **Telemetry Web Interface:** Real-time visualization of robot state and diagnostics.

#### 3.1.4. Cloud Gateway Node (Raspberry Pi 5)
-   **Implementation:** Dedicated ROS 2 Humble node (`a2_cloud_gateway_node_design.md`).
-   **Responsibilities:** Manages all communication with cloud-hosted Application Programming Interface (API) endpoints. Sends curated local state/sensor data to Master Shared State System (MSSS) & cloud LLMs. Receives directives and text for speech. Manages Conversational Speech Model (CSM) audio streaming. Handles network errors.
    -   **Phase 1:** Uses polling for fetching directives. Basic error handling and retries.

### 3.3. Local Development Mode

The A2 system supports a local-first development mode that enables full functionality without cloud dependencies, optimizing for rapid iteration and cost control during development phases.

#### 3.3.1. Local Mistral 7B Deployment
-   **Implementation:** llama.cpp with CUDA support on RTX 4080 system
-   **Model Configuration:** Mistral-7B-Instruct-v0.2 with 4-bit quantization (Q4_K_M)
-   **Memory Usage:** ~4GB VRAM (fits comfortably in 16GB RTX 4080 system)
-   **Performance:** 15-25 tokens/second inference speed
-   **Integration:** FastAPI wrapper service with ROS 2 Humble bridge

#### 3.3.2. Direct ROS 2 Humble Integration for LLMs
-   **Local Large Language Model (LLM) Node:** `local_llm_service.py` provides same interface as cloud LLMs
-   **State Management:** Uses Local Shared State Cache (Local Shared State Cache (LSSC)) instead of cloud Master Shared State System (MSSS)
-   **Decision Making:** Simplified rule-based system with local Large Language Model (LLM) augmentation
-   **Fallback Strategy:** Graceful degradation to rule-based responses if Large Language Model (LLM) unavailable

#### 3.3.3. Config-Based Cloud/Local Switching
-   **Configuration File:** `deployment_config.yaml` controls service routing
-   **Environment Variables:** `A2_DEPLOYMENT_MODE=[local|cloud|hybrid]`
-   **Runtime Switching:** Services can be toggled without system restart
-   **Development Workflow:**
    1. Develop and test locally (free)
    2. Validate with cloud services (minimal cost)
    3. Deploy to cloud for demonstrations

#### 3.3.4. Local Development Benefits
-   **Cost Optimization:** Zero cloud costs during development
-   **Iteration Speed:** No network latency for Large Language Model (LLM) responses
-   **Offline Capability:** Full functionality without internet connection
-   **Debugging:** Direct access to all system components
-   **Resource Control:** Predictable performance on known hardware

### 3.2. Cloud Tier Components (RunPod or similar)

#### 3.2.1. Multi-Large Language Model (LLM) Swarm (Containerized Services)
-   **Base Model:** Unified Mistral 7B Instruct (or similar). Role-specific LoRA adapters.
-   **Components & Interfaces:**
    -   **Communication Large Language Model (LLM) (`a2_communication_llm_cloud_interface.md`):** NLU, dialogue, persona, expression formulation. Triggers Conversational Speech Model (CSM).
    -   **Decision Large Language Model (LLM) (`a2_decision_llm_cloud_interface.md`):** Context integration, goal setting, attention, high-level behavioral directives.
    -   **Motion Large Language Model (LLM) (`a2_motion_llm_cloud_interface.md`):** Translates directives into abstract motion plans.
-   **Interaction:** Via Master Shared State System (MSSS).
    -   **Phase 1:** LLMs may be simplified or mocked to test pipeline. Focus on data flow and basic directive generation.

#### 3.2.2. Conversational Speech Model (Conversational Speech Model (CSM) - Containerized Service)
-   **Implementation:** Based on Sesame Conversational Speech Model (CSM) (`csm_tts_integration.md`).
-   **Responsibilities:** Generates natural-sounding speech with a custom cloned voice. Receives text from cloud Communication Large Language Model (LLM). Streams audio to Cloud Gateway.
    -   **Phase 1:** Focus on successful voice cloning and reliable audio streaming.

#### 3.2.3. Master Shared State System (Master Shared State System (MSSS) - Cloud)
-   **Implementation:** Redis-backed database with a FastAPI layer (`a2_master_shared_state_cloud_design.md`).
-   **Responsibilities:** Authoritative system state, inter-Large Language Model (LLM) coordination, cloud-side conflict resolution.
    -   **Phase 1:** Simplified conflict resolution (hierarchical). Robot Gateway polls for updates.

## 4. Data Flow and Communication Strategy

### 4.1. Onboard Data Loops

-   **P0 Safety Loop (Teensy 4.1):** Sensor -> P0 Logic -> Actuator Enable Control / Alert to Raspberry Pi 5.
-   **P1 Reflex Loop (Raspberry Pi 5):** Local Sensor Processing -> Local Shared State Cache (LSSC) -> Fast Path Reflex System (FPRS) -> P1 Command -> Execution Router -> Hardware Interface Layer (HIL) -> Actuators.
-   **Local Perception Loop (Raspberry Pi 5 <> Local RTX 4080 system):** Raw Sensors (Intel RealSense D455, Mic on Raspberry Pi 5) -> Data to RTX 4080 system -> Vision/Speech-to-Text (STT) Processing on RTX 4080 system -> Processed Data back to Raspberry Pi 5 (Local Shared State Cache (LSSC) / Cloud Gateway).

### 4.2. Hybrid Local-Cloud Interaction Loop (Simplified for Phase 1)

1.  **Input:** User speaks. Local Mic (Raspberry Pi 5) -> Audio to Local Speech-to-Text (STT) (RTX 4080 system) -> Transcribed text.
2.  **Uplink Context:** Cloud Gateway (Raspberry Pi 5) sends transcribed text and summarized local state (from Local Shared State Cache (LSSC)) to relevant cloud Large Language Model (LLM) APIs (e.g., Communication Large Language Model (LLM) or Decision Large Language Model (LLM) via Master Shared State System (MSSS) update).
3.  **Cloud Processing:**
    -   Cloud LLMs process input and current Master Shared State System (MSSS) state.
    -   Communication Large Language Model (LLM) formulates text response and expression hints, posts to Master Shared State System (MSSS), and triggers Conversational Speech Model (CSM).
    -   Decision Large Language Model (LLM) updates goals/behavioral mode, posts to Master Shared State System (MSSS).
    -   Motion Large Language Model (LLM) generates abstract motion plan based on Master Shared State System (MSSS) directives, posts to Master Shared State System (MSSS).
    -   Master Shared State System (MSSS) Conflict Resolution (simplified) finalizes directives in `resolved_robot_directives_queue`.
    -   Conversational Speech Model (CSM) streams synthesized audio.
4.  **Downlink Directives & Audio:**
    -   Cloud Gateway (Raspberry Pi 5) polls Master Shared State System (MSSS) for `resolved_robot_directives_queue`, receives motion/gesture/expression commands.
    -   Simultaneously, Cloud Gateway receives audio stream from Conversational Speech Model (CSM).
5.  **Local Execution:**
    -   Cloud Gateway updates Local Shared State Cache (LSSC) with new directives and publishes audio stream.
    -   Local Audio Playback node (Raspberry Pi 5) plays audio.
    -   Execution Router (Raspberry Pi 5) reads directives from Local Shared State Cache (LSSC), applies P0/P1 overrides, and commands Hardware Interface Layer (HIL) to move actuators.

### 4.3. Inter-Cloud Communication

-   Cloud LLMs, Master Shared State System (MSSS), and Conversational Speech Model (CSM) interact via internal cloud network APIs or message queues.

### 4.4. WebSocket State Streaming

The A2 system implements real-time state synchronization using WebSocket connections to replace polling-based communication, enabling more responsive and efficient cloud-local coordination.

#### 4.4.1. Event-Driven State Updates
-   **WebSocket Connection:** Persistent bidirectional connection between Cloud Gateway and Master Shared State System (MSSS)
-   **State Change Events:** Master Shared State System (MSSS) pushes updates immediately when state changes occur
-   **Selective Updates:** Only changed state components are transmitted (delta compression)
-   **Priority Queuing:** Critical updates (safety, expressions) sent with higher priority

#### 4.4.2. Local State Prediction During Network Latency
-   **Predictive Modeling:** Local system predicts likely state changes during network delays
-   **Rollback Mechanism:** Corrections applied when actual cloud state differs from prediction
-   **Confidence Scoring:** Predictions include confidence levels for decision making
-   **Graceful Degradation:** System continues with local predictions if connection lost

#### 4.4.3. Connection Management
-   **Automatic Reconnection:** Exponential backoff retry strategy for dropped connections
-   **Heartbeat Protocol:** Regular ping/pong to detect connection health
-   **State Resynchronization:** Full state sync on reconnection to ensure consistency
-   **Fallback to Polling:** Automatic fallback if WebSocket connection unstable

#### 4.4.4. Performance Benefits
-   **Reduced Latency:** Immediate state updates vs polling intervals
-   **Lower Bandwidth:** Delta updates vs full state transfers
-   **Better Responsiveness:** Real-time reaction to cloud decisions
-   **Resource Efficiency:** Reduced CPU usage from eliminated polling loops

## 5. Latency Management and Responsiveness

-   **Local Tiers (P0, P1):** Designed for <10ms and <75ms responses respectively.
-   **Cloud Interaction Loop (Phase 1 Target):** Aim for <2-2.5 seconds from end of user speech to start of robot's spoken and embodied response. This is challenging and requires optimization at each step.
-   **Text-to-Speech (TTS) Streaming:** Conversational Speech Model (CSM) audio streaming is critical. Target <700ms from text available at Conversational Speech Model (CSM) to first audio chunk playback on robot.
-   **Local RTX 4080 system Tasks:** Vision/Speech-to-Text (STT) processing expected within 50-300ms depending on model complexity.

## 6. Benefits of Hybrid Architecture (Reiteration)

-   **Scalable Intelligence:** Cloud handles heavy AI lifting.
-   **Real-time Safety & Control:** Local systems ensure immediate responsiveness.
-   **Cost Efficiency:** Optimized use of local vs. cloud compute.
-   **Advanced Features:** Enables use of large, powerful AI models.
-   **Modularity:** Clear separation for development and upgrades.

### 6.1. Expression-Driven Latency Targets

The A2 Robot's expressive capabilities require carefully tuned latency targets that balance technical constraints with natural interaction patterns. These targets are designed around human perception of responsive, emotionally coherent robotic behavior.

#### 6.1.1. Reflex Responses: <75ms (Unchanged)
-   **P0 Safety Responses:** <10ms for emergency stops and collision avoidance
-   **P1 Fast Reflexes:** <75ms for environmental reactions (loud sounds, movement detection)
-   **Justification:** Matches human startle response times, maintains believable reactive behavior
-   **Implementation:** Local processing only, no cloud dependency

#### 6.1.2. Speech Onset to Motion: <200ms
-   **Gesture Initiation:** Physical movement begins within 200ms of speech start
-   **Expression Synchronization:** Facial/head expressions align with vocal emotional tone
-   **Breathing Simulation:** Subtle platform movements synchronized with speech rhythm
-   **Justification:** Maintains tight coupling between verbal and physical expression, mimics natural human speech-gesture coordination

#### 6.1.3. Full Interaction Loop: 2.5-4s Acceptable Range
-   **Optimal Target:** 2.5 seconds from user speech end to robot response start
-   **Acceptable Range:** Up to 4 seconds for complex reasoning tasks
-   **Breakdown:**
    -   Speech-to-Text (STT) Processing: 500-800ms
    -   Cloud Large Language Model (LLM) Reasoning: 1000-2000ms
    -   Text-to-Speech (TTS) Generation: 700-1000ms
    -   Motion Planning: 200-400ms
-   **Justification:** Matches natural conversation pacing, allows for thoughtful responses

#### 6.1.4. Expression Quality vs Latency Trade-offs
-   **High-Priority Expressions:** Curiosity, alertness, acknowledgment (<200ms)
-   **Medium-Priority Expressions:** Emotional responses, complex gestures (<500ms)
-   **Low-Priority Expressions:** Narrative gestures, environmental scanning (<1000ms)
-   **Degradation Strategy:** Simpler expressions used when latency constraints cannot be met

#### 6.1.5. Context-Aware Latency Adaptation
-   **Conversation State:** Faster responses during active dialogue, slower during ambient mode
-   **User Patience Modeling:** Adapt timing based on user interaction patterns
-   **Expression Urgency:** Safety-related expressions always prioritized
-   **Predictive Pre-computation:** Anticipate likely responses to reduce perceived latency

## 7. Evolution Beyond Phase 1

Post-Phase 1, the architecture will be enhanced with:
-   More sophisticated conflict resolution in Master Shared State System (MSSS) and Execution Router.
-   Push-based state synchronization (WebSockets/gRPC) for Master Shared State System (MSSS)-Local Shared State Cache (LSSC).
-   Advanced network resilience and more detailed "offline personality" scripts.
-   Full implementation of all designed local perception and reflex modules.
-   Richer expressive capabilities and more nuanced Large Language Model (LLM) coordination.
-   Preparation for physical expansion (arms, legs) by maturing motion planning and state representation.

This hybrid architecture, implemented iteratively starting with a focused Phase 1, provides a robust and adaptable framework for the A2 Robot to achieve its goal of intelligent and expressive human-robot interaction.


===============================================
PHASE 1 EXECUTIVE SUMMARY
===============================================

- --
title: "Phase 1 Executive Summary"
type: guide
status: active
created: "2024-01-01"
updated: "2024-01-01"
- --

# A2 Robot Phase 1: Executive Summary

## Overview

This document provides detailed information and implementation guidance.

> **Document Status:** CURRENT
> **Last Updated:** 2025-05-28
> **Version:** 1.0.0
> **Scope:** Phase 1

## Table of Contents

- [Overview](#overview)
- [Vision](#vision)
- [Key Differentiators](#key-differentiators)
- [Revised Implementation Timeline (8 Weeks)](#revised-implementation-timeline-8-weeks)
  - [Weeks 1-2: Hardware Foundation](#weeks-1-2-hardware-foundation)
  - [Weeks 3-4: Expressive Primitives](#weeks-3-4-expressive-primitives)
  - [Weeks 5-6: Local AI Integration](#weeks-5-6-local-ai-integration)
  - [Weeks 7-8: Cloud Services](#weeks-7-8-cloud-services)
- [Technical Architecture](#technical-architecture)
  - [Hardware Stack](#hardware-stack)
  - [Software Architecture](#software-architecture)
  - [AI Personality Framework](#ai-personality-framework)
- [Cost Management Strategy](#cost-management-strategy)
  - [Development Phase Budget](#development-phase-budget)
  - [Local-First Approach](#local-first-approach)
- [Risk Mitigation](#risk-mitigation)
  - [Technical Risks](#technical-risks)
  - [Business Risks](#business-risks)
- [Success Metrics](#success-metrics)
  - [Phase 1 Completion Criteria](#phase-1-completion-criteria)
  - [User Experience Targets](#user-experience-targets)
- [Next Phase Roadmap](#next-phase-roadmap)
  - [Phase 2: Enhanced Intelligence (Weeks 9-16)](#phase-2-enhanced-intelligence-weeks-9-16)
  - [Phase 3: Physical Expansion (Weeks 17-24)](#phase-3-physical-expansion-weeks-17-24)
  - [Phase 4: Ecosystem Integration (Weeks 25-32)](#phase-4-ecosystem-integration-weeks-25-32)
- [Investment Requirements](#investment-requirements)
  - [Immediate Needs (Phase 1)](#immediate-needs-phase-1)
  - [Future Phases (Estimated)](#future-phases-estimated)
- [Competitive Advantage](#competitive-advantage)
  - [Technical Moats](#technical-moats)
  - [Market Positioning](#market-positioning)
- [Project Team & Resources](#project-team-resources)
  - [Core Development Team](#core-development-team)
  - [External Resources](#external-resources)
- [Conclusion](#conclusion)

- --

## Vision

Create an expressive robotic desk assistant that combines cutting-edge conversational AI with emotionally expressive physical movements, inspired by bird and dog biomechanics.

## Key Differentiators

1. **Multi-Agent AI Personality System**: Specialized Mistral 7B LoRA adapters for distinct behavioral aspects
2. **Expressive Motion Design**: Non-anthropomorphic movements that convey clear emotional intent
3. **Tight Speech-Motion Coupling**: Sub-200ms synchronization between verbal and physical expression
4. **Local-First Development**: Cost-optimized approach using RTX 4080 system for development

## Revised Implementation Timeline (8 Weeks)

### Weeks 1-2: Hardware Foundation

- **Goal**: Establish reliable robot ↔ computer communication
- **Deliverable**: Real-time sensor data in ROS, single servo control
- **Success Metric**: 100Hz Inertial Measurement Unit (IMU) data streaming, servo sine wave demo

### Weeks 3-4: Expressive Primitives

- **Goal**: Implement first emotional expressions
- **Deliverable**: "Curious head tilt" and posture adjustments
- **Success Metric**: User recognition of emotions >80%

### Weeks 5-6: Local AI Integration

- **Goal**: Voice interaction with personality
- **Deliverable**: Local Speech-to-Text (STT) + rule-based responses
- **Success Metric**: <1s transcription, contextual responses

### Weeks 7-8: Cloud Services

- **Goal**: Enhanced AI capabilities
- **Deliverable**: Large Language Model (LLM) integration, quality comparisons
- **Success Metric**: <2.5s full interaction loop

## Technical Architecture

### Hardware Stack

- **Brain**: Raspberry Pi 5 (ROS 2 Humble)
- **Reflexes**: Teensy 4.1 (FreeRTOS, 1kHz safety loop)
- **Motion**: 6 Dynamixel servos + 3 L16 actuators
- **Perception**: Intel RealSense D455 D405 + ReSpeaker Mic Array

### Software Architecture

- **Local Tier**: Safety reflexes, motion control, sensor processing
- **Cloud Tier**: Multi-Large Language Model (LLM) swarm, advanced reasoning, voice synthesis
- **Hybrid Communication**: WebSocket state streaming, local prediction

### AI Personality Framework

- **Communication Agent**: Natural conversation, emotional expression
- **Decision Agent**: Goal setting, behavioral mode selection
- **Motion Agent**: Physical expression, gesture generation
- **Conflict Resolution**: Multi-agent state synchronization (Master Shared State System (MSSS))

## Cost Management Strategy

### Development Phase Budget

- **Training/Fine-tuning**: <$1,000 total
- **Daily Operations**: $10-50/day during active development
- **Hardware**: One-time $3,500 investment

### Local-First Approach

- **Development**: 100% local (RTX 4080 system + Mistral 7B)
- **Testing**: Minimal cloud validation
- **Demonstration**: Cloud services for optimal performance
- **Production**: Hybrid local/cloud based on usage patterns

## Risk Mitigation

### Technical Risks

1. **Motion Expressiveness**: Extensive user testing, iterative refinement
2. **AI Coherence**: Multi-agent conflict resolution, state management
3. **Hardware Reliability**: Redundant safety systems, graceful degradation
4. **Latency Requirements**: Local processing fallbacks, predictive caching

### Business Risks

1. **Cost Overruns**: Strict budget monitoring, local-first development
2. **Timeline Delays**: Weekly milestone validation, scope adjustment
3. **Market Fit**: Early user feedback integration, pivot capability

## Success Metrics

### Phase 1 Completion Criteria

- **Hardware Integration**: All sensors and actuators operational
- **Basic Expressions**: 5+ recognizable emotional states
- **Voice Interaction**: Functional conversation capability
- **System Reliability**: 95% uptime during 8-hour test sessions

### User Experience Targets

- **Emotional Recognition**: >80% accuracy in user studies
- **Response Latency**: <2.5s full interaction loop
- **Motion Smoothness**: <5% jerk in motion primitives
- **Conversation Quality**: Coherent multi-turn dialogues

## Next Phase Roadmap

### Phase 2: Enhanced Intelligence (Weeks 9-16)

- Advanced multi-agent coordination
- Contextual memory and learning
- Complex multi-step task execution
- Environmental interaction capabilities

### Phase 3: Physical Expansion (Weeks 17-24)

- Arm and hand integration
- Object manipulation capabilities
- Mobile platform development
- Advanced perception systems

### Phase 4: Ecosystem Integration (Weeks 25-32)

- Smart home integration
- Multi-robot coordination
- Cloud service marketplace
- Developer SDK and Application Programming Interface (API)

## Investment Requirements

### Immediate Needs (Phase 1)

- **Hardware**: $3,500 (already acquired)
- **Cloud Services**: $1,500 (8-week development)
- **Development Tools**: $500 (software licenses)
- **Total Phase 1**: $5,500

### Future Phases (Estimated)

- **Phase 2**: $8,000 (enhanced AI, sensors)
- **Phase 3**: $15,000 (arms, mobility, manufacturing)
- **Phase 4**: $25,000 (ecosystem, scaling)

## Competitive Advantage

### Technical Moats

1. **Expression Engine**: Proprietary motion primitive catalog
2. **Multi-Agent AI**: Novel personality architecture
3. **Local-Cloud Hybrid**: Cost-optimized deployment strategy
4. **Real-time Integration**: Sub-200ms speech-motion coupling

### Market Positioning

- **Target**: Tech enthusiasts, developers, early adopters
- **Price Point**: $2,000-$3,500 (competitive with high-end tablets)
- **Distribution**: Direct sales, developer community, tech conferences
- **Support**: Open-source components, active community engagement

## Project Team & Resources

### Core Development Team

- **Lead Engineer**: System integration, ROS 2 Humble architecture
- **AI Specialist**: Large Language Model (LLM) fine-tuning, multi-agent coordination
- **Mechanical Engineer**: Motion design, hardware optimization
- **UX Designer**: Interaction patterns, user testing

### External Resources

- **Cloud Infrastructure**: RunPod, Replicate (AI services)
- **Manufacturing**: Local 3D printing, electronics assembly
- **Testing**: User study participants, beta tester community
- **Advisory**: Robotics researchers, AI industry experts

## Conclusion

The A2 Robot represents a significant advancement in personal robotics, combining state-of-the-art AI with expressive physical design. The local-first development approach ensures cost-effective iteration while maintaining the capability to leverage cloud services for enhanced performance.

Phase 1 focuses on establishing core functionality with a clear path to advanced capabilities in subsequent phases. The 8-week timeline is aggressive but achievable given the modular architecture and iterative development approach.

Success in Phase 1 will demonstrate the viability of the technical approach and provide a foundation for scaling to a full product ecosystem. The combination of emotional expressiveness, conversational AI, and cost-effective deployment positions A2 as a compelling entry in the emerging personal robotics market.

**Key Decision Points:**
- Week 4: Evaluate motion expressiveness, adjust primitive catalog
- Week 6: Assess local AI performance, validate cloud integration strategy
- Week 8: Phase 1 completion review, Phase 2 planning and resource allocation

**Next Steps:**
1. Finalize hardware setup and ROS 2 Humble workspace configuration
2. Begin Week 1 milestone: sensor integration and basic communication
3. Establish weekly review cadence with stakeholders
4. Set up development environment and cost monitoring systems


===============================================
BILL OF MATERIALS
===============================================

---
title: "Bill Of Materials"
type: guide
status: active
created: "2024-01-01"
updated: "2025-06-04"
---

# A2 Robot: Bill of Materials (BOM) - Hybrid Architecture

## Overview

This document provides detailed information and implementation guidance for the A2 Robot.

> **Document Status:** CURRENT
> **Last Updated:** 2025-06-04
> **Version:** 1.1.0
> **Scope:** Phase 1, updated with recent acquisitions.

## Table of Contents

- [Overview](#overview)
- [1. Introduction](#1-introduction)
- [2. Core Controllers & Computing](#2-core-controllers-computing)
- [3. Actuators & Motion Components](#3-actuators-motion-components)
- [4. Sensors - Enhanced Configuration](#4-sensors-enhanced-configuration)
  - [4.1 Primary Vision & Depth Sensing System](#4-1-primary-vision-depth-sensing-system)
  - [4.2 Inertial Measurement Units](#4-2-inertial-measurement-units)
  - [4.3 Audio & Additional Sensors](#4-3-audio-additional-sensors)
- [5. Power System](#5-power-system)
- [6. Thermal Management](#6-thermal-management)
- [7. Wiring, Connectors, and Passive Components](#7-wiring-connectors-and-passive-components)
  - [7.1 Wiring Recommendations by Subsystem](#7-1-wiring-recommendations-by-subsystem)
  - [7.2 Components](#7-2-components)
- [8. Mechanical and 3D Printing](#8-mechanical-and-3d-printing)
- [9. Tools & Shop Supplies](#9-tools-shop-supplies)
- [10. Peripherals & Control Interfaces](#10-peripherals-control-interfaces)
- [11. Software & Cloud Services](#11-software-cloud-services)
- [Configuration Notes & Best Practices](#configuration-notes-best-practices)
  - [Sensor Integration Priority:](#sensor-integration-priority)
  - [Component Selection Rationale:](#component-selection-rationale)
  - [Future Expansion Considerations:](#future-expansion-considerations)
  - [Testing Recommendations:](#testing-recommendations)

---

## 1. Introduction

This document lists the key hardware components required for building the A2 Robotic Assistant, aligned with the hybrid cloud-local architecture and Phase 1 implementation priorities. It has been updated with recent purchases and consolidated previously inventoried parts. Quantities are for one A2 head/neck assembly, unless otherwise specified.

**Configuration Update (May-June 2025):**
- Dual depth sensing system: Arducam ToF Camera (short range) + Intel RealSense D455 (long range)
- Primary IMUs: SparkFun ICM-20948 (9DoF) for superior orientation tracking, supplemented by Alinan GY-BMI160 and HiLetgo MPU9250.
- Optimized component selection from available inventory and new orders.
- Comprehensive update to tools, wiring, and mechanical components.

**Status Legend:**
-   **[HAVE]**: Component is in hand.
-   **[ORDERED]**: Component has been ordered, awaiting delivery.
-   **[NEED]**: Component needs to be acquired.
-   **[DEV_KIT]**: Part of a larger development kit or assortment.
-   **[PRIMARY]**: Primary component choice for this configuration.
-   **[BACKUP]**: Backup or alternative component.

## 2. Core Controllers & Computing

| Component                     | Qty | Status    | Notes / Recent Order (if applicable)                                     | Purpose                                                                  |
| :---------------------------- | :-- | :-------- | :----------------------------------------------------------------------- | :----------------------------------------------------------------------- |
| Raspberry Pi 5 (8GB)          | 1   | [HAVE]    | Assumed from previous inventory discussions                              | Main onboard computer, ROS 2 hub, Cloud Gateway, Fast Path Reflexes    |
| Teensy 4.1                    | 1   | [HAVE]    | Ordered: Amazon Order ID 112-5411160-3985815 (SparkFun Teensy 4.1)        | Ultra-fast safety (P0), L16 feedback, IMU acquisition                    |
| NVIDIA RTX 4080 (or similar)  | 1   | [HAVE]    | Assumed available in local Host PC/System                                | Local GPU tasks (Vision, STT, Telemetry UI)                              |
| MicroSD Card for Pi (>=64GB)  | 1   | [HAVE]    | Assumed                                                                  | OS for Raspberry Pi 5                                                    |
| U2D2 (Dynamixel Interface)    | 1   | [HAVE]    | Assumed from previous ROBOTIS order info                                 | USB to Dynamixel TTL communication                                       |
| USB Logic Analyzer 24MHz 8CH  | 1   | [HAVE]    | Ordered: Amazon Order ID 112-8854467-8905013 (HiLetgo)                    | Debugging digital signals (UART, I2C, SPI)                               |
| TP-Link WiFi 6 USB Adapter    | 1   | [HAVE]    | Ordered: Amazon Order ID 114-5535205-5034632 (Archer TX20U Plus)          | Wireless networking for Pi 5 or Host PC                                  |

## 3. Actuators & Motion Components

| Component                     | Qty | Status    | Notes / Recent Order                                                     | Purpose                                                              |
| :---------------------------- | :-- | :-------- | :----------------------------------------------------------------------- | :------------------------------------------------------------------- |
| Actuonix L16-100-35-12-P      | 6   | [HAVE]    | User has 6 total units for Stewart platform                             | Linear actuators for Stewart platform (6-DOF motion)                |
| DYNAMIXEL XL430-W250-T        | 3   | [HAVE]    | Assumed from previous ROBOTIS order (Need 2, 3 were mentioned as ordered) | Head Yaw, Head Pitch servos                                          |
| DYNAMIXEL XL330-M288-T        | 1   | [HAVE]    | Assumed from previous ROBOTIS order                                      | Head Roll servo                                                      |
| Robot Cable-X3P (180mm)       | ~5+ | [HAVE]    | Assumed from previous ROBOTIS order (10 were mentioned)                  | Dynamixel servo cables                                               |
| BTS7960 H-Bridge Drivers      | 6   | [HAVE]    | Ordered: 2x (112-3951268-7013851), 4x (112-1405192-7827442)               | Spare/backup motor drivers (replaced by DRV8871)                     |
| Universal/Ball Joints for L16 | 25  | [HAVE]    | Ordered: 5x (114-1459081-4873013), 20x (112-1405192-7827442 & 114-7331204-4948211) | General robot joints (Stewart ball joints will be 3D printed)        |
| LX-224 Serial Bus Servo       | 5   | [HAVE]    | Ordered: Amazon Order ID 114-7331204-4948211 (5 Packs)                   | Alternative/development servos for specific applications             |
| MG996R Digital Servo Motor    | 4   | [HAVE]    | Ordered: Amazon Order ID 112-4249421-8645060 (4-Pack)                    | General purpose servos for various experimental movements            |
| Servo Horns (25T)             | 20  | [HAVE]    | Ordered: Amazon Order ID 112-6409710-6610613 (DaFuRui 20Pcs)             | Attachments for MG996R servos                                        |
| Pan Tilt Servo Mount Bracket  | 5   | [HAVE]    | Ordered: Amazon Order ID 112-6409710-6610613 (DaFuRui 5 Sets)            | Mounting for MG996R servos                                           |
| PCA9685 16-Channel PWM Driver | 2   | [HAVE]    | Ordered: Amazon Order ID 112-4249421-8645060 (HiLetgo 2pcs)              | PWM signal generation for multiple servos                              |

### 3.1 Stewart Platform Components (Additional Items Needed)

| Component                     | Qty | Status    | Notes / Supplier                                                        | Purpose                                                              |
| :---------------------------- | :-- | :-------- | :----------------------------------------------------------------------- | :------------------------------------------------------------------- |
| DRV8871 Motor Drivers         | 6   | [NEED]    | HiLetgo 2pcs per order - need 3 orders for 6 total                     | L16 motor control with current limiting (replaces BTS7960)          |
| 1000µF/25V Capacitors         | 6   | [NEED]    | One per DRV8871 for motor ripple suppression                           | Local energy storage at each motor driver                           |
| 0.2Ω 1W Resistors            | 6   | [NEED]    | Current limit setting for DRV8871 (sets 2A limit)                      | Protects L16 actuators from overcurrent                            |
| Shielded Cable (3-conductor)  | 10m | [NEED]    | For L16 position feedback wiring                                       | Noise reduction on analog position signals                          |
| M5 or M6 Threaded Inserts     | 24  | [HAVE]    | User has heat-set inserts in inventory                                 | Ball joint mounting in 3D printed plates                           |
| 10mm-15mm Aluminum Plate      | 2   | [OPTIONAL]| For base and top plates if not 3D printing                            | Alternative to 3D printed PETG plates                              |

## 4. Sensors - Enhanced Configuration

### 4.1 Primary Vision & Depth Sensing System

| Component                     | Qty | Status         | Mounting & Configuration                                             | Purpose                                                              |
| :---------------------------- | :-- | :------------- | :------------------------------------------------------------------ | :------------------------------------------------------------------- |
| Intel RealSense D455          | 1   | [HAVE][PRIMARY]| Main forward-facing camera position                                  | Long-range depth (0.4m-9m), RGB vision, stereo depth, 90° FOV      |
| Arducam ToF Camera (0.43MP)   | 1   | [HAVE][PRIMARY]| Mounted 50-75mm above RealSense, aligned forward                    | Short-range precision depth (0.2m-2m), 30fps depth stream          |
| SparkFun Qwiic ToF Imager VL53L5CX | 1 | [HAVE][BACKUP]| Alternative multi-zone ToF for testing / specific applications      | Multi-zone distance measurements (8x8 zones), 63° FoV                |

**Dual Depth Sensing Strategy:**
- **Near field (0.2m - 2m)**: Arducam ToF provides millimeter-accurate depth for desk-level interactions
- **Far field (0.4m - 9m)**: RealSense D455 for room awareness and human tracking
- **Sensor fusion zone (0.4m - 2m)**: Combined data for enhanced accuracy

### 4.2 Inertial Measurement Units

| Component                          | Qty | Status         | Configuration                                                       | Purpose                                                              |
| :--------------------------------- | :-- | :------------- | :------------------------------------------------------------------ | :------------------------------------------------------------------- |
| SparkFun ICM-20948 (9DoF) Qwiic   | 2   | [HAVE][PRIMARY]| I2C addresses 0x69 (head), 0x68 (base)                            | Primary IMUs - 9-axis with magnetometer for absolute orientation    |
| Alinan GY-BMI160 (6DoF) Modules   | 10  | [HAVE][BACKUP] | Available for testing and additional sensing points                 | Development/backup IMUs - 6-axis, lower power consumption           |
| HiLetgo MPU9250 (9-Axis) Modules  | 2   | [HAVE][BACKUP] | Additional 9-axis IMUs for expanded sensing/testing                 | Alternative 9-axis IMU with gyroscope, accelerometer, magnetometer   |

**IMU Configuration Notes:**
- ICM-20948 provides superior sensor fusion with onboard DMP (Digital Motion Processor)
- Use TCA9548A I2C multiplexer to manage multiple ICM-20948/MPU9250 modules
- BMI160 modules reserved for future expansion or testing

### 4.3 Audio & Additional Sensors

| Component                     | Qty | Status    | Usage Notes                                                              | Purpose                                                              |
| :---------------------------- | :-- | :-------- | :----------------------------------------------------------------------- | :------------------------------------------------------------------- |
| ReSpeaker USB Mic Array v2    | 1   | [HAVE]    | Ordered: Amazon Order ID 112-1405192-7827442 (seeed studio)              | Voice capture, direction of arrival, noise cancellation             |
| VL53L0X ToF Modules (I2C)     | 6   | [HAVE]    | Ordered: Amazon Order ID 112-0546181-8765840 (Coliao 6pcs)                | Proximity sensing for collision avoidance                           |
| INA219 Current Sensors        | 6   | [HAVE]    | Ordered: Amazon Order ID 114-5592439-0382644 (ACEIRMC 6pcs INA219). Plus 1x INA260 (112-1405192-7827442) | Real-time power monitoring and optimization                         |
| ADS1115 16-bit ADC            | 4   | [HAVE]    | Ordered: Amazon Order ID 114-5191971-3141847 (WWZMDiB 4Pcs)               | Precision analog input beyond Teensy's 12-bit ADC                   |
| HC-SR04 Ultrasonic            | 1   | [HAVE]    | Assumed                                                                  | Backup distance sensing                                              |
| Micro Limit Switches (KW12-3) | 2   | [HAVE]    | Ordered: Amazon Order ID 112-0036692-8397027 (HiLetgo 10pcs, 2 for robot, spares available) | End-stop detection, safety interlocks                                |
| Electret Mic Amplifier MAX4466| 2   | [HAVE]    | Ordered: Amazon Order ID 114-1878550-8954646 (HiLetgo 2pcs)              | General audio input, sound detection                                 |

## 5. Power System

| Component                                 | Qty | Status    | Notes / Recent Order                                                     | Purpose                                                          |
| :---------------------------------------- | :-- | :-------- | :----------------------------------------------------------------------- | :--------------------------------------------------------------- |
| MEAN WELL LRS-350-12 Switching PSU        | 1   | [HAVE] | Ordered: Amazon Order ID 114-5535205-5034632 (350W, 12V, 29A)             | Main 12V power supply                                            |
| Mean Well LRS-200-12 Switching PSU        | 1   | [HAVE] | Ordered: Amazon Order ID 112-4351023-3474653 (200W, 12V, 17A)             | Secondary 12V power supply or backup                               |
| DC-DC Buck Converter (5A type)            | 2   | [HAVE]    | Ordered: Amazon Order ID 112-6842156-7392224 (2 Pack)                     | 12V to 5V conversion (Pi, USB devices)                           |
| DC-DC Buck Converter (3A type, e.g. MP1584) | 1   | [HAVE]/[NEED] | Assumed from previous inventory (for 3.3V rail)                        | 12V to 3.3V conversion (Teensy, some sensors)                    |
| 10000μF/25V Capacitors                    | 10  | [HAVE]    | Ordered: Amazon Order ID 112-0405329-0720246 (Cermant 10pcs)              | Power rail buffering (main 12V)                                  |
| 470μF Capacitors (various voltages)       | ~3+ | [DEV_KIT] | Assumed from capacitor assortments                                       | Power rail buffering (5V, 3.3V rails)                            |
| Anmbest MOSFET Module 15A/400W            | 5   | [HAVE] | DC 5V-36V 15A (Max 30A) 400W Dual High-Power MOSFET Trigger Switch      | System soft-start and E-stop control (use 2, 3 spare)             |
| IRLB8721 N-Channel MOSFET                 | 10  | [HAVE] | Ordered: Amazon Order ID 114-0051741-1953077 (Pack of 10, ALLECIN)        | Spare MOSFETs for general use                                      |
| Momentary Push Button Switch (19MM, Red LED)| 2   | [HAVE] | Ordered: Amazon Order ID 114-5915170-1170620 (DMWD, Pack of 2)           | Emergency Stop button, general input                             |
| 5V 10A Power Supply Adapter               | 1   | [HAVE] | Ordered: Amazon Order ID 112-4249421-8645060 (ALITOVE 5V 10A)             | Dedicated 5V power for Pi/sensors                                |
| AC Inlet Module Plug w/ Fuse & Switch     | 3   | [HAVE] | Ordered: Amazon Order ID 112-8464891-6877850 (3 Pieces)                  | Main power input with fuse protection                            |
| TVS Diodes (SMAJ6.0A)                     | 200 | [HAVE] | Ordered: Amazon Order ID 114-5940127-8696211 (Pack of 200)               | ESD protection for sensitive circuits                            |

## 6. Thermal Management

| Component                     | Qty | Status    | Specifications                                                           | Purpose                                                          |
| :---------------------------- | :-- | :-------- | :----------------------------------------------------------------------- | :--------------------------------------------------------------- |
| 40mm x 10mm 5V Fans           | 2   | [HAVE]    | Ordered: Amazon Order ID 114-3131348-5593819 (WINSINN 40mm Fan 5V)        | Raspberry Pi 5 cooling, electronics bay ventilation              |
| 40mm x 10mm 12V Fans          | 2   | [HAVE]    | Ordered: Amazon Order ID 114-3131348-5593819 (WINSINN 40mm Fan 12V)       | Auxiliary cooling for drivers or other components                |
| 60mm x 15mm 12V Fan           | 1   | [NEED]    | For power supply cooling if enclosed                                     | PSU thermal management                                           |
| Raspberry Pi 5 Heatsink Kit   | 1   | [NEED]    | Official or Geekworm compatible                                         | CPU/RAM passive cooling                                          |
| Thermal Pads (Various)        | Kit | [NEED]    | 0.5mm, 1mm, 2mm thickness assortment                                   | BTS7960 drivers, MOSFETs, voltage regulators                     |
| M3 Fan Guards (40mm)          | 2   | [NEED]    | Wire or plastic mesh guards                                             | Fan protection                                                   |

## 7. Wiring, Connectors, and Passive Components

### 7.1 Wiring Recommendations by Subsystem

**Power Distribution:**
- 12V Main: 16-18 AWG silicone wire (red/black)
- 5V Rails: 20 AWG silicone wire
- 3.3V Rail: 22 AWG silicone wire
- Ground: Star ground configuration at PSU

**High-Speed Data:**
- USB 3.0 (Cameras): Shielded cables, <2m length
- I2C Buses: Twisted pair with ground, pull-up resistors at master
- UART (Teensy): Shielded 3-conductor, hardware flow control

**Sensor Wiring:**
- IMUs: Keep I2C traces <30cm, use multiplexer for address conflicts
- ToF Sensors: Individual I2C addresses via software configuration

### 7.2 Components
| Component                               | Qty    | Status    | Notes / Recent Order                                                     |
| :-------------------------------------- | :----- | :-------- | :----------------------------------------------------------------------- |
| ELEGOO Dupont Wire Jumper Kit           | 1 kit  | [HAVE] | Ordered: Amazon Order ID 112-0546181-8765840 (120pcs, M-F, M-M, F-F)     |
| Silicone Insulated Wire (various AWG)   | Various| [HAVE]    | 12 AWG (112-9555280-9629855), 16 AWG (112-7949203-4381016), 18 AWG (114-8351289-8884250), 20 AWG (114-3124785-7063436 & 112-4249421-8645060), 22 AWG (114-9334443-9658661 & 112-6409710-6610613) |
| Heat Shrink Tubing Kit                  | 1 kit  | [HAVE]    | Ordered: Amazon Order ID 112-4249421-8645060 (Eventronic 400 Pcs)        |
| JST-XH Connector Kit                    | 1 kit  | [HAVE]    | Ordered: Amazon Order ID 112-8464891-6877850 (Taiss 560PCS)              |
| Ferrite Clips/Beads                     | 1 kit  | [HAVE]    | Ordered: Amazon Order ID 114-7491290-1111462 (Tamicy 60 Pieces)          |
| Resistor Assortment Kit                 | 1 kit  | [HAVE]    | Ordered: Amazon Order ID 114-8249194-1864212 (ALLECIN 50 Values)         |
| Ceramic Capacitor Assortment Kit        | 1 kit  | [HAVE]    | Ordered: Amazon Order ID 114-7491290-1111462 (BOJACK 15 Type Values)     |
| Electrolytic Capacitor Assortment Kit   | 1 kit  | [HAVE]    | Ordered: Amazon Order ID 114-7491290-1111462 (ALLECIN 24 Values)         |
| Diode Assortment (incl. 1N400x)         | 1 kit  | [HAVE]    | Ordered: Amazon Order ID 114-7491290-1111462 (ALLECIN 20Values)          |
| Logic Level Converter (Bi-Directional)  | 10     | [HAVE]    | Ordered: Amazon Order ID 112-7112902-8685809 (HiLetgo 10pcs)             |
| HiLetgo PCA9548A/TCA9548A I2C Multiplexer | 1      | [HAVE]    | Ordered: Amazon Order ID 114-1878550-8954646 (HiLetgo)                   |
| Zip Ties Assorted Sizes                 | 800    | [HAVE]    | Ordered: 2x 400 pack (112-0546181-8765840 & 112-6505497-4089049)          |
| Goupchn SMD IC Test Hook Clips            | 1 set  | [HAVE] | Ordered: Amazon Order ID 112-0546181-8765840 (12pcs, 6 colors)           |
| PCB Power Distribution Board Kit        | 3      | [HAVE] | Ordered: Amazon Order ID 112-1485028-3101838 (WayinTop 2x) & 112-8464891-6877850 (WayinTop 1x) | For organized power distribution                               |
| Dupont Connector Kit                    | 1 kit  | [HAVE] | Ordered: Amazon Order ID 112-8464891-6877850 (IWISS 1550PCS)             | Connectors for various signals and power                           |
| 40 Pin Headers Right Angle              | 10     | [HAVE] | Ordered: Amazon Order ID 112-8464891-6877850 (10Pcs)                     | Prototyping and modular connections                                |
| Nylon Spade Quick Disconnect Connectors | 1 kit  | [HAVE] | Ordered: Amazon Order ID 112-8464891-6877850 (TICONN 200 Pcs)            | For quick, insulated electrical connections                        |
| 3 Prong AC Power Cord Cable             | 1      | [HAVE] | Ordered: Amazon Order ID 112-8464891-6877850 (Standard 5ft)              | Power input for PSU                                              |
| Heat Shrink Wire Connectors (Assorted)  | Various| [HAVE] | Ordered: Amazon Order ID 112-8464891-6877850 (TICONN 120Pcs, haisstronica 260PCS), 114-8351289-8884250 (160 Pcs Solder Seal Wire Connectors) | Durable and insulated electrical connections                     |
| Fuse Holder & Glass Fuses Kit           | 1 kit  | [HAVE] | Ordered: Amazon Order ID 112-7112902-8685809 (BOJACK 5x20 mm Fuse)        | Circuit protection for various subsystems                          |
| Double Sided PCB Board Prototype Kit    | 2 kits | [HAVE] | Ordered: Amazon Order ID 112-7112902-8685809 (ELEGOO 32 Pcs) & (Smraza 104pcs) | For custom circuit prototyping                                   |
| PCB Mount Screw Terminal Block Connector| 70     | [HAVE] | Ordered: Amazon Order ID 112-7112902-8685809 (BOJACK Blue 70)             | Secure wire connections on PCBs                                  |
| Transistors Assortment Kit              | 1 kit  | [HAVE] | Ordered: Amazon Order ID 114-1597981-4005045 (BOJACK 10 Values 250 Pcs) | For general purpose electronics, switching, signal amplification    |
| DSI FPC Flexible Cable for RPi 5        | 1      | [HAVE] | Ordered: Amazon Order ID 114-8994120-8891455 (Waveshare 200mm)            | Connect Raspberry Pi 5 to DSI displays                             |

## 8. Mechanical and 3D Printing

| Component                               | Qty    | Status    | Notes / Recent Order                                                     |
| :-------------------------------------- | :----- | :-------- | :----------------------------------------------------------------------- |
| Prusament PETG Filament (Urban Grey)    | 1kg    | [HAVE] | Ordered: Amazon Order ID 112-8854467-8905013                               |
| Prusament PETG Filament (Clear)         | 1kg    | [HAVE] | Ordered: Amazon Order ID 112-8854467-8905013                               |
| Prusament PETG Filament (Prusa Orange)  | 1kg    | [HAVE] | Ordered: Amazon Order ID 112-0546181-8765840                               |
| TPU Filament                            | 1kg    | [HAVE] | Ordered: Amazon Order ID 112-8719961-3969841 (OVERTURE TPU Black)         |
| Heat-Set M3 Inserts                     | 540+   | [HAVE] | Ordered: 2x (114-9165275-7216259 & 112-6342618-3157845) ruthex M2/M3/M4/M5, 100x (114-3572439-9584218) ruthex M3, 100x (114-7033994-9953000) HANGLIFE M2.5 |
| M3 Screw Assortment                     | 2 kits | [HAVE] | Ordered: 2x (112-4289762-2114662 & 114-7331204-4948211) Kadrick 2240 Pcs M3 |
| M4 Hex Spacer/Standoff/Screw/Nut Kit    | 1 kit  | [HAVE] | Ordered: Amazon Order ID 112-8854467-8905013 (Swpeet 192Pcs, M4)         |
| RC Shocks (100-110mm)                   | 5      | [HAVE] | Ordered: 1x (112-6203986-3013863) Pothyes 110mm, 4x (112-9243889-5033021) RCLions 100mm |
| ShareGoo Rod Ends / M3 Ball Studs       | 25     | [HAVE] | Ordered: 5x (112-1405192-7827442) Metal M3 Ball, 10x (112-1405192-7827442) M3 Tie Rod End, 10x (114-7331204-4948211) M3 Tie Rod End |
| LM8UU Linear Ball Bearings              | 12     | [HAVE] | Ordered: Amazon Order ID 112-2193158-5570640 (12 Pcs)                    |
| Spherical Plain Bearings                | 6      | [HAVE] | Ordered: 4x GE5C (112-2193158-5570640), 2x GE17C (112-2193158-5570640)  |
| Aluminum Sheet Metal                    | 2      | [HAVE] | Ordered: Amazon Order ID 112-4249421-8645060 (2 Pieces 12x12x1/16")     |
| Nylon Hex Standoff Screw Nut Kit        | 1 kit  | [HAVE] | Ordered: Amazon Order ID 112-4249421-8645060 (Rrina 432Pcs M2.5 M3 M4)   |
| M2 M3 M4 M5 Hex Button Head Screw Kit   | 1 kit  | [HAVE] | Ordered: Amazon Order ID 112-6409710-6610613 (DYWISHKEY 1220 Pieces)     |
| Metric O-Ring Kit                       | 1 kit  | [HAVE] | Ordered: Amazon Order ID 114-7331204-4948211 (XBVV 419 PCS)              |
| Rubber Bands (Assorted Sizes)           | 1 pack | [HAVE] | Ordered: Amazon Order ID 114-7331204-4948211 (AMUU 0.5 lb)               |
| Flanged Ball Bearing (F623ZZ)           | 10     | [HAVE] | Ordered: Amazon Order ID 114-7331204-4948211 (HiPicco 10pcs)             |
| M3 Hex Aluminum Standoff Spacer Kit     | 1 kit  | [HAVE] | Ordered: Amazon Order ID 114-7331204-4948211 (Swpeet 48Pcs)              |
| Aluminum Rods (4mm x 100mm)             | 20     | [HAVE] | Ordered: Amazon Order ID 114-7331204-4948211 (DYWISHKEY 20 Pieces)       |
| Compression Springs Assortment Kit      | 1 kit  | [HAVE] | Ordered: Amazon Order ID 114-7109129-7687417 (Dianrui 300PCS)             |
| Neoprene Foam Anti Vibration Pads       | 8      | [HAVE] | Ordered: Amazon Order ID 114-7109129-7687417 (8 Pieces Black Neoprene)   |
| Bungee Shock Cords (1/8" x 65ft)        | 1      | [HAVE] | Ordered: Amazon Order ID 114-7109129-7687417 (1/8"" Bungee Shock Cords)  |
| PCIe NVMe M.2 Mounting Screws Kit       | 1 kit  | [HAVE] | Ordered: Amazon Order ID 114-7109129-7687417 (PCIe NVMe M.2 Mounting Screws) |
| Set Screw Collars (3.05mm Bore)         | 20     | [HAVE] | Ordered: Amazon Order ID 114-7331204-4948211 (uxcell 20pcs)              |
| Anti-Vibration Damping Rubber Balls     | 12     | [HAVE] | Ordered: Amazon Order ID 114-4356554-9950616 (Vgoohobby 12Pack)         |
| Plastic Cable Wire Carrier Drag Chain   | 1      | [HAVE] | Ordered: Amazon Order ID 114-7109129-7687417 (Befenybay 10mmx11mm)      |
| PETG Filament (Black)                   | 1kg    | [HAVE] | Ordered: Amazon Order ID 112-8719961-3969841 (CREALITY PETG Black)      |
| PETG Filament (Black, OVERTURE)         | 1kg    | [HAVE] | Ordered: Amazon Order ID 112-8719961-3969841 (OVERTURE PETG Black)      |
| PLA Filament (Black & White)            | 2kg    | [HAVE] | Ordered: Amazon Order ID 112-8719961-3969841 (OVERTURE PLA Black & White) |
| Cast Acrylic Sheets (12x12x1/8")        | 4      | [HAVE] | Ordered: Amazon Order ID 112-4249421-8645060 (Toolinhand 4 Pack)         |

## 9. Tools & Shop Supplies

| Component                               | Qty    | Status    | Notes / Recent Order                                                     |
| :-------------------------------------- | :----- | :-------- | :----------------------------------------------------------------------- |
| Creality K1 Max 3D Printer              | 1      | [HAVE] | Ordered: Amazon Order ID 112-0305162-5349824                               |
| Filament Dryer                          | 1      | [HAVE] | Ordered: Amazon Order ID 112-8719961-3969841 (Creality Space Pi)         |
| Soldering Station (Hakko FX888DX)       | 1      | [HAVE] | Ordered: Amazon Order ID 112-0981746-1643420                               |
| Soldering Iron Station (YIHUA 926 III)  | 1      | [HAVE] | Ordered: Amazon Order ID 112-4249421-8645060                               |
| Digital Multimeter                      | 1      | [HAVE] | Ordered: Amazon Order ID 112-4249421-8645060 (AstroAI)                     |
| Digital Calipers                        | 1      | [HAVE] | Ordered: Amazon Order ID 112-0981746-1643420 (Kynup)                       |
| Ratcheting Crimping Tool Set            | 1      | [HAVE] | Ordered: Amazon Order ID 112-8464891-6877850 (iCrimp 8 PCS)                |
| Dupont Crimping Tool Kit                | 1      | [HAVE] | Ordered: Amazon Order ID 112-4249421-8645060 (Taiss)                       |
| Precision Screwdriver (Electric)        | 1      | [HAVE] | Ordered: Amazon Order ID 112-4632464-0516249 (Fanttik S1 Pro)             |
| Magnetic Helping Hands Soldering Station| 1      | [HAVE] | Ordered: Amazon Order ID 112-9202986-3936253                               |
| Helping Hands Soldering Tool            | 1      | [HAVE] | Ordered: Amazon Order ID 112-4249421-8645060 (KLSKKJ)                      |
| Hot Air Rework Station (YIHUA 959D)     | 1      | [HAVE] | Ordered: Amazon Order ID 112-8726219-5300203                               |
| Creality 3D Printer Tool Kit (74Pcs)    | 1      | [HAVE] | Ordered: Amazon Order ID 114-8625362-2917037                               |
| Creality K1 Hotend Upgrades Kit         | 1      | [HAVE] | Ordered: Amazon Order ID 114-8625362-2917037 (Unicorn K1 Series)           |
| Creality K1C Nozzles (Tri-Metal Steel-Tipped) | 1 kit | [HAVE] | Ordered: Amazon Order ID 114-8625362-2917037 (4 PCS)                      |
| Official Creality K1 Nozzle Kits (Hardened Steel)| 1 kit | [HAVE] | Ordered: Amazon Order ID 112-5956825-4668261 (5PCS)                     |
| 3D Printer Nozzle Cleaning Kit          | 1      | [HAVE] | Ordered: Amazon Order ID 114-8625362-2917037                               |
| Isopropyl Alcohol (91%)                 | 12-pack| [HAVE] | Ordered: Amazon Order ID 114-8625362-2917037 (Amazon Basics 16 Fl oz)      |
| Heat-Set Insert Soldering Tips (Ruthex) | 2 sets | [HAVE] | Ordered: 2x (114-0210131-2615428 & 114-3572439-9584218)                   |
| Tip Tinner (Thermaltronics TMT-TC-2)    | 1      | [HAVE] | Ordered: Amazon Order ID 112-4557585-9365060                               |
| Soldering Tip Cleaner (Brass Sponge)    | 1      | [HAVE] | Ordered: Amazon Order ID 112-0799291-2625855 (Kaisiking)                  |
| Tin Lead Rosin Core Solder Wire         | 2      | [HAVE] | Ordered: 2x (112-0799291-2625855 & 112-4249421-8645060)                     |
| Adjustable Wrench (Crescent 4")         | 1      | [HAVE] | Ordered: Amazon Order ID 114-1459081-4873013                               |
| Digital Oscilloscope (Siglent SDS1204X-E)| 1      | [HAVE] | Ordered: Amazon Order ID 114-9334443-9658661                               |
| Cordless Rotary Tool Kit (Fanttik F2)   | 1      | [HAVE] | Ordered: Amazon Order ID 114-2707101-3421812                               |
| Polishing Buffing Wheel Kit             | 1      | [HAVE] | Ordered: Amazon Order ID 114-2707101-3421812 (134PCS)                      |
| Micro Sander (MicroLux®)                | 1      | [HAVE] | Ordered: Amazon Order ID 112-5987732-4193817 (Includes tips & pads)        |
| Replacement Sanding Pads (400 Grit)     | 1      | [HAVE] | Ordered: Amazon Order ID 112-7605723-8157026 (4 Shapes, 15 Each)           |
| Portable Label Printer (Brady M211)     | 1      | [HAVE] | Ordered: Amazon Order ID 112-5221552-4732219 (Plus 1 Label Roll)           |
| Bit Adapter (1/4 to 4mm Hex)            | 4      | [HAVE] | Ordered: Amazon Order ID 114-3803878-3579420 (4 Pack)                      |
| 74LSxx Series Logic ICs (20pcs)         | 1 kit  | [HAVE] | Ordered: Amazon Order ID 114-3315513-8139432 (20pcs)                       |
| Teyleten Robot TB6612FNG Motor Driver   | 3      | [HAVE] | Ordered: Amazon Order ID 112-4463371-7695467 (Pack of 3)                   |
| Creality Clog Poke (Nozzle Cleaning)    | 1      | [HAVE] | Ordered: Amazon Order ID 112-3691013-2530663                               |
| Creality K1 Extruder with Motor         | 1      | [HAVE] | Ordered: Amazon Order ID 112-3691013-2530663                               |
| Textured PEI Build Plate (K1 Max)       | 1      | [HAVE] | Ordered: Amazon Order ID 112-5956825-4668261                               |
| Micro Cutter (Hakko-CHP-170)            | 2      | [HAVE] | Ordered: Amazon Order ID 112-5956825-4668261 (2x)                          |
| Precision Flush Cutter (Beaditive)      | 1      | [HAVE] | Ordered: Amazon Order ID 112-8719961-3969841                               |
| Solder Wicks                            | 2      | [HAVE] | Ordered: Amazon Order ID 114-2498996-8759460 (Lesnow 2 Pieces)             |
| Storage Organizers                      | 2      | [HAVE] | Ordered: CRAFTSMAN (112-6505497-4089049), Stalwart (114-4706669-5820242)   |
| ESD Anti-Static Table Mat Kit           | 1      | [HAVE] | Ordered: Amazon Order ID 112-6505497-4089049 (Bertech)                     |
| ELEGOO UNO Project Super Starter Kit    | 1      | [DEV_KIT] | Ordered: Amazon Order ID 112-5435279-1325838                              |
| Liquid Flux No-Clean (Chip Quik)        | 1      | [HAVE] | Ordered: Amazon Order ID 112-2385756-5916220                               |
| Desiccant Silica Gel Beads              | 2      | [HAVE] | Ordered: Dry & Dry (112-4557585-9365060), Vbeijll (112-8719961-3969841)    |
| Claw Hammer                             | 1      | [HAVE] | Ordered: Amazon Order ID 112-8464891-6877850 (Olympia Tools)               |

## 10. Peripherals & Control Interfaces

| Component                               | Qty | Status    | Notes / Recent Order                                                     | Purpose                                                          |
| :-------------------------------------- | :-- | :-------- | :----------------------------------------------------------------------- | :--------------------------------------------------------------- |
| Raspberry Pi Official 7 Inch Touch Screen | 1   | [HAVE]    | Ordered: Amazon Order ID 112-2725869-7216223                              | On-robot display for UI/debug                                    |
| Small Cavity Speakers (1W 8 Ohm)        | 8   | [HAVE]    | Ordered: Amazon Order ID 114-1863676-8996245 (Treedix 8pcs)              | Audio output for robot voice, sound effects                      |
| Audio Amplifier Board (PAM8302)         | 2   | [HAVE]    | Ordered: Amazon Order ID 112-0823601-0041024 (HiLetgo 2pcs)              | Amplification for small speakers                                 |
| Logitech MX Master 3S Mouse             | 1   | [HAVE]    | Ordered: Amazon Order ID 114-4818898-0396227                               | External input for development/testing                           |
| LOFREE Flow Mechanical Keyboard         | 1   | [HAVE]    | Ordered: Amazon Order ID 114-9173115-1205857                               | External input for development/testing                           |
| HDMI Cable (8K, 25FT)                   | 2   | [HAVE]    | Ordered: Amazon Order ID 112-2551283-8637035 (Highwings 2x)                | Display connection from host PC or Pi                              |
| DC Power Pigtail Barrel Plug Connector Cable | 10 pairs | [HAVE] | Ordered: Amazon Order ID 112-4249421-8645060 (MILAPEAK 10 Pairs)       | Standard DC power connections                                    |

## 11. Software & Cloud Services
-   **RunPod Account:** For hosting cloud LLMs, CSM, MSSS.
-   **Hugging Face Account:** For models.
-   **OS:** Ubuntu 22.04 for Pi & Host PC, RTOS for Teensy.
-   **Core Software:** ROS 2 Humble, Python 3.10, Docker, CUDA, PyTorch.

## Configuration Notes & Best Practices

### Sensor Integration Priority:
1.  **Phase 1 Week 1-2**: ICM-20948 IMUs via Teensy I2C
2.  **Phase 1 Week 3-4**: RealSense D455 via USB 3.0 to Pi
3.  **Phase 1 Week 5-6**: Arducam ToF integration and sensor fusion
4.  **Phase 1 Week 7-8**: Full multi-sensor integration testing

### Component Selection Rationale:
-   **ICM-20948 over BMI160/MPU9250**: Integrated magnetometer provides absolute heading reference, with others as backups.
-   **Dual Depth Cameras**: Eliminates blind spots in near-field manipulation zone.
-   **INA219 Current Sensing**: Enables power-aware behavior adaptation.
-   **Multiple Power Supplies**: Provides flexibility for power management and future expansion.

### Future Expansion Considerations:
-   Reserve I2C addresses 0x70-0x77 for future sensors.
-   Keep BMI160/MPU9250 modules accessible for limb tracking (quadruped evolution).
-   USB hub on Pi 5 to support additional cameras or peripherals.

### Testing Recommendations:
1.  Validate I2C bus stability with all sensors connected.
2.  Benchmark depth camera fusion algorithms.
3.  Characterize power consumption under various loads.
4.  Test thermal performance under continuous operation.

[PRIMARY]: #primary-components
[BACKUP]: #backup-components


===============================================
EXPRESSIVE MOTION PRIMITIVES
===============================================

- --
title: "Expressive Motion Primitives"
type: guide
status: active
created: "2024-01-01"
updated: "2024-01-01"
- --

# A2 Robot: Expressive Motion Primitives Catalog

## Overview

This document provides detailed information and implementation guidance.

> **Document Status:** CURRENT
> **Last Updated:** 2025-05-28
> **Version:** 1.0.0
> **Scope:** Phase 1

## Table of Contents

- [Overview](#overview)
- [1. Design Philosophy](#1-design-philosophy)
  - [Core Principles](#core-principles)
  - [Emotional Axes](#emotional-axes)
- [2. Hardware Constraints](#2-hardware-constraints)
  - [Head Assembly (6-DOF)](#head-assembly-6-dof)
  - [Platform (3-DOF + vertical)](#platform-3-dof-vertical)
- [3. Motion Primitive Categories](#3-motion-primitive-categories)
  - [3.1 Attention Primitives (Bird-inspired)](#3-1-attention-primitives-bird-inspired)
    - [CURIOUS_HEAD_TILT](#curious_head_tilt)
    - [ALERT_SCAN](#alert_scan)
    - [FOCUS_LOCK](#focus_lock)
  - [3.2 Emotional Expression Primitives](#3-2-emotional-expression-primitives)
    - [EXCITEMENT_BOUNCE](#excitement_bounce)
    - [DISAPPOINTMENT_DROOP](#disappointment_droop)
    - [UNCERTAINTY_WOBBLE](#uncertainty_wobble)
  - [3.3 Social Interaction Primitives](#3-3-social-interaction-primitives)
    - [GREETING_NOD](#greeting_nod)
    - [PLAYFUL_PEEK](#playful_peek)
    - [DEFENSIVE_RETREAT](#defensive_retreat)
  - [3.4 Functional Movement Primitives](#3-4-functional-movement-primitives)
    - [SPEAKER_TRACKING](#speaker_tracking)
    - [BREATHING_SIMULATION](#breathing_simulation)
    - [ENVIRONMENTAL_SCAN](#environmental_scan)
- [4. Motion Blending and Transitions](#4-motion-blending-and-transitions)
  - [4.1 Primitive Combination Rules](#4-1-primitive-combination-rules)
    - [Additive Blending](#additive-blending)
    - [Sequential Chaining](#sequential-chaining)
    - [Interrupt Handling](#interrupt-handling)
  - [4.2 Context-Aware Scaling](#4-2-context-aware-scaling)
    - [Intensity Modulation](#intensity-modulation)
    - [Environmental Adaptation](#environmental-adaptation)
- [5. Implementation Architecture](#5-implementation-architecture)
  - [5.1 Motion Primitive Engine](#5-1-motion-primitive-engine)
  - [5.2 ROS 2 Humble Integration](#5-2-ros-2-integration)
- [6. Testing and Validation](#6-testing-and-validation)
  - [6.1 Motion Quality Metrics](#6-1-motion-quality-metrics)
    - [Smoothness Assessment](#smoothness-assessment)
    - [Emotional Expressiveness](#emotional-expressiveness)
  - [6.2 Hardware Validation](#6-2-hardware-validation)
    - [Joint Limit Compliance](#joint-limit-compliance)
    - [Performance Benchmarking](#performance-benchmarking)
- [7. Future Enhancements](#7-future-enhancements)
  - [7.1 Machine Learning Integration](#7-1-machine-learning-integration)
    - [Motion Style Transfer](#motion-style-transfer)
    - [Procedural Animation](#procedural-animation)
  - [7.2 Advanced Expression Capabilities](#7-2-advanced-expression-capabilities)
    - [Micro-Expression System](#micro-expression-system)
    - [Environmental Interaction](#environmental-interaction)

- --

## 1. Design Philosophy

### Core Principles

- **Non-anthropomorphic Expression**: Avoid human mimicry while maintaining emotional readability
- **Biomechanical Inspiration**: Draw from bird head movements (quick, precise) and dog postures (alertness states)
- **Function-Expression Duality**: Every movement serves both practical and emotional purposes
- **Contextual Appropriateness**: Movements scale based on interaction intensity

### Emotional Axes

- **Valence**: Positive (approach) ← → Negative (withdraw)
- **Arousal**: High energy ← → Low energy
- **Dominance**: Confident ← → Submissive

## 2. Hardware Constraints

### Head Assembly (6-DOF)

- Neck Base: 3 Dynamixel servos (yaw ±90°, pitch ±45°, roll ±30°)
- Head Unit: 3 Dynamixel servos (yaw ±45°, pitch ±30°, roll ±20°)
- Maximum angular velocity: 180°/s
- Recommended smooth operation: 60-120°/s

### Platform (3-DOF + vertical)

- L16-R Actuators: 140mm stroke, 75mm/s max speed
- Platform height adjustment: ±70mm from neutral
- Platform tilt: ±15° pitch, ±10° roll
- Weight capacity considerations for smooth motion

## 3. Motion Primitive Categories

### 3.1 Attention Primitives (Bird-inspired)

#### CURIOUS_HEAD_TILT
- **Emotional Intent**: Curiosity, interest, processing
- **Components**: neck_yaw + neck_pitch
- **Trajectory**:
  ```yaml
  duration: 800ms
  phases:
    - name: "approach"
      duration: 300ms
      neck_yaw: 0° → 25°
      neck_pitch: 0° → -15°
      easing: "ease_out"
    - name: "hold"
      duration: 200ms
      neck_yaw: 25°
      neck_pitch: -15°
    - name: "return"
      duration: 300ms
      neck_yaw: 25° → 0°
      neck_pitch: -15° → 0°
      easing: "ease_in"
  ```
- **Variations**: Left tilt (negative yaw), intensity scaling (±5° to ±35°)

#### ALERT_SCAN
- **Emotional Intent**: Vigilance, environmental awareness
- **Components**: neck_yaw + head_yaw
- **Trajectory**:
  ```yaml
  duration: 2000ms
  phases:
    - name: "left_sweep"
      duration: 600ms
      neck_yaw: 0° → -60°
      head_yaw: 0° → -20°
      easing: "linear"
    - name: "center_pause"
      duration: 200ms
      neck_yaw: -60° → 0°
      head_yaw: -20° → 0°
    - name: "right_sweep"
      duration: 600ms
      neck_yaw: 0° → 60°
      head_yaw: 0° → 20°
      easing: "linear"
    - name: "return"
      duration: 600ms
      neck_yaw: 60° → 0°
      head_yaw: 20° → 0°
  ```

#### FOCUS_LOCK
- **Emotional Intent**: Intense concentration, target acquisition
- **Components**: All head DOF
- **Trajectory**:
  ```yaml
  duration: 1200ms
  phases:
    - name: "approach"
      duration: 400ms
      neck_pitch: 0° → -20°
      head_pitch: 0° → -10°
      neck_yaw: 0° → target_yaw
      easing: "ease_out"
    - name: "micro_adjust"
      duration: 400ms
      head_yaw: 0° → ±3° (oscillating)
      head_pitch: -10° → -10°±2° (micro-movements)
      frequency: 4Hz
    - name: "settle"
      duration: 400ms
      all_joints: → target_position
      easing: "ease_in"
  ```

### 3.2 Emotional Expression Primitives

#### EXCITEMENT_BOUNCE
- **Emotional Intent**: Joy, enthusiasm, positive arousal
- **Components**: platform_height + neck_pitch
- **Trajectory**:
  ```yaml
  duration: 1500ms
  phases:
    - name: "anticipation"
      duration: 200ms
      platform_height: 0mm → -20mm
      neck_pitch: 0° → 10°
    - name: "bounce_sequence"
      duration: 1000ms
      platform_height: -20mm → +40mm → -10mm → +30mm → 0mm
      neck_pitch: 10° → -15° → 5° → -10° → 0°
      bounce_count: 3
      decay_factor: 0.7
    - name: "settle"
      duration: 300ms
      all_joints: → neutral
      easing: "ease_out"
  ```

#### DISAPPOINTMENT_DROOP
- **Emotional Intent**: Sadness, deflation, negative valence
- **Components**: platform_height + neck_pitch + head_pitch
- **Trajectory**:
  ```yaml
  duration: 2000ms
  phases:
    - name: "slow_descent"
      duration: 1200ms
      platform_height: 0mm → -40mm
      neck_pitch: 0° → 25°
      head_pitch: 0° → 15°
      easing: "ease_in_out"
    - name: "hold_low"
      duration: 500ms
      maintain_positions: true
    - name: "partial_recovery"
      duration: 300ms
      platform_height: -40mm → -20mm
      neck_pitch: 25° → 15°
      head_pitch: 15° → 8°
  ```

#### UNCERTAINTY_WOBBLE
- **Emotional Intent**: Confusion, indecision, processing difficulty
- **Components**: neck_roll + head_roll
- **Trajectory**:
  ```yaml
  duration: 1800ms
  phases:
    - name: "wobble_sequence"
      duration: 1500ms
      neck_roll: 0° → 15° → -15° → 10° → -10° → 0°
      head_roll: 0° → -8° → 8° → -5° → 5° → 0°
      timing: "irregular" # Non-uniform intervals
      frequency_variation: 0.8Hz to 1.2Hz
    - name: "settle"
      duration: 300ms
      all_joints: → neutral
  ```

### 3.3 Social Interaction Primitives

#### GREETING_NOD
- **Emotional Intent**: Acknowledgment, politeness, social engagement
- **Components**: neck_pitch + platform_height
- **Trajectory**:
  ```yaml
  duration: 1000ms
  phases:
    - name: "bow_down"
      duration: 400ms
      neck_pitch: 0° → 30°
      platform_height: 0mm → -15mm
      easing: "ease_out"
    - name: "pause"
      duration: 200ms
      maintain_positions: true
    - name: "return"
      duration: 400ms
      neck_pitch: 30° → 0°
      platform_height: -15mm → 0mm
      easing: "ease_in"
  ```

#### PLAYFUL_PEEK
- **Emotional Intent**: Mischief, playfulness, social invitation
- **Components**: platform_height + neck_yaw + head_yaw
- **Trajectory**:
  ```yaml
  duration: 2500ms
  phases:
    - name: "duck_down"
      duration: 500ms
      platform_height: 0mm → -50mm
      neck_pitch: 0° → 20°
    - name: "peek_left"
      duration: 600ms
      neck_yaw: 0° → -45°
      head_yaw: 0° → -20°
      neck_pitch: 20° → 10°
    - name: "peek_right"
      duration: 600ms
      neck_yaw: -45° → 45°
      head_yaw: -20° → 20°
    - name: "pop_up"
      duration: 400ms
      platform_height: -50mm → +20mm
      neck_yaw: 45° → 0°
      head_yaw: 20° → 0°
      neck_pitch: 10° → -5°
    - name: "settle"
      duration: 400ms
      all_joints: → neutral
  ```

#### DEFENSIVE_RETREAT
- **Emotional Intent**: Caution, withdrawal, negative social response
- **Components**: platform_height + neck_pitch + platform_tilt
- **Trajectory**:
  ```yaml
  duration: 1500ms
  phases:
    - name: "recoil"
      duration: 300ms
      platform_height: 0mm → -30mm
      neck_pitch: 0° → 35°
      platform_pitch: 0° → -8°
      easing: "ease_out"
    - name: "hold_defensive"
      duration: 800ms
      maintain_positions: true
      micro_movements:
        neck_roll: ±2° (nervous tremor)
        frequency: 3Hz
    - name: "cautious_return"
      duration: 400ms
      platform_height: -30mm → -10mm
      neck_pitch: 35° → 20°
      platform_pitch: -8° → -3°
  ```

### 3.4 Functional Movement Primitives

#### SPEAKER_TRACKING
- **Emotional Intent**: Attention, engagement, active listening
- **Components**: neck_yaw + neck_pitch + head_yaw
- **Parameters**: target_position (x, y, z)
- **Trajectory**:
  ```yaml
  duration: variable (500-1500ms based on distance)
  phases:
    - name: "calculate_angles"
      neck_yaw_target: atan2(target_y, target_x)
      neck_pitch_target: atan2(target_z, sqrt(target_x² + target_y²))
      head_yaw_fine: (neck_yaw_target % 15°) # Fine adjustment
    - name: "smooth_approach"
      duration: calculated
      neck_yaw: current → neck_yaw_target
      neck_pitch: current → neck_pitch_target
      head_yaw: current → head_yaw_fine
      easing: "ease_in_out"
      max_velocity: 90°/s
  ```

#### BREATHING_SIMULATION
- **Emotional Intent**: Life-like presence, calm state indication
- **Components**: platform_height + neck_pitch (subtle)
- **Trajectory**:
  ```yaml
  duration: 4000ms (breathing cycle)
  loop: continuous
  phases:
    - name: "inhale"
      duration: 1500ms
      platform_height: baseline → baseline + 8mm
      neck_pitch: baseline → baseline - 2°
      easing: "ease_in_out"
    - name: "hold_inhale"
      duration: 500ms
      maintain_positions: true
    - name: "exhale"
      duration: 1800ms
      platform_height: baseline + 8mm → baseline - 3mm
      neck_pitch: baseline - 2° → baseline + 1°
      easing: "ease_in_out"
    - name: "hold_exhale"
      duration: 200ms
      platform_height: baseline - 3mm → baseline
      neck_pitch: baseline + 1° → baseline
  ```

#### ENVIRONMENTAL_SCAN
- **Emotional Intent**: Situational awareness, data gathering
- **Components**: neck_yaw + head_yaw + head_pitch
- **Trajectory**:
  ```yaml
  duration: 8000ms
  phases:
    - name: "horizon_scan"
      duration: 3000ms
      neck_yaw: -90° → +90° → 0°
      head_pitch: 0° (maintain level)
      velocity: 60°/s
    - name: "vertical_scan"
      duration: 2000ms
      neck_pitch: -30° → +20°
      head_pitch: -15° → +10°
      neck_yaw: 0° (maintain center)
    - name: "detail_focus"
      duration: 2000ms
      # Focus on detected objects/faces
      target_sequence: [object1, object2, face1]
      dwell_time: 600ms per target
    - name: "return_neutral"
      duration: 1000ms
      all_joints: → neutral_position
  ```

## 4. Motion Blending and Transitions

### 4.1 Primitive Combination Rules

#### Additive Blending
- **Compatible Primitives**: Different joint groups can run simultaneously
- **Example**: BREATHING_SIMULATION + SPEAKER_TRACKING
- **Implementation**: Joint-level motion addition with conflict resolution

#### Sequential Chaining
- **Smooth Transitions**: End state of primitive A becomes start state of primitive B
- **Transition Duration**: 200-500ms interpolation period
- **Example**: ALERT_SCAN → FOCUS_LOCK → GREETING_NOD

#### Interrupt Handling
- **Priority System**: Safety (P0) > Reflexes (P1) > Expressions (P2) > Ambient (P3)
- **Graceful Degradation**: Lower priority motions fade out over 300ms
- **Resume Capability**: Interrupted motions can resume from current position

### 4.2 Context-Aware Scaling

#### Intensity Modulation
```python
def scale_primitive(primitive, intensity_factor):
    """Scale motion primitive based on emotional intensity (0.0 to 2.0)"""
    scaled_primitive = primitive.copy()

    # Scale angular displacements
    for joint in scaled_primitive.joints:
        joint.angle_delta *= intensity_factor

    # Scale timing (higher intensity = faster motion)
    scaled_primitive.duration *= (1.0 / sqrt(intensity_factor))

    # Clamp to hardware limits
    return clamp_to_limits(scaled_primitive)
```markdown

#### Environmental Adaptation
- **Noise Level**: Reduce subtle movements in noisy environments
- **Lighting Conditions**: Enhance visibility-critical movements in low light
- **User Proximity**: Scale movement amplitude based on distance to user
- **Social Context**: Formal vs casual interaction movement sets

## 5. Implementation Architecture

### 5.1 Motion Primitive Engine

```python
class MotionPrimitiveEngine:
    def __init__(self):
        self.active_primitives = {}
        self.joint_controllers = {}
        self.conflict_resolver = ConflictResolver()

    def execute_primitive(self, primitive_name, parameters=None):
        primitive = self.load_primitive(primitive_name)
        if parameters:
            primitive = self.apply_parameters(primitive, parameters)

        # Check for conflicts with active primitives
        conflicts = self.conflict_resolver.check_conflicts(primitive, self.active_primitives)

        if conflicts:
            self.handle_conflicts(conflicts)

        # Execute primitive
        self.active_primitives[primitive.id] = primitive
        self.schedule_motion(primitive)

    def blend_motions(self):
        """Combine all active primitive motions into final joint commands"""
        final_commands = {}

        for primitive in self.active_primitives.values():
            current_frame = primitive.get_current_frame()

            for joint, command in current_frame.items():
                if joint not in final_commands:
                    final_commands[joint] = []
                final_commands[joint].append((command, primitive.priority))

        # Resolve conflicts and blend
        return self.conflict_resolver.resolve(final_commands)
```markdown

### 5.2 ROS 2 Humble Integration

```python
class MotionPrimitiveNode(Node):
    def __init__(self):
        super().__init__('motion_primitive_node')

        # Publishers
        self.joint_cmd_pub = self.create_publisher(
            JointCommand, '/hardware/joint_commands', 10)

        # Subscribers
        self.expression_sub = self.create_subscription(
            ExpressionCommand, '/behavior/expression_command',
            self.expression_callback, 10)

        # Services
        self.execute_primitive_srv = self.create_service(
            ExecutePrimitive, '/motion/execute_primitive',
            self.execute_primitive_callback)

        # Motion engine
        self.engine = MotionPrimitiveEngine()

        # Control loop timer (100Hz)
        self.control_timer = self.create_timer(0.01, self.control_loop)

    def control_loop(self):
        """Main control loop - blend and publish joint commands"""
        joint_commands = self.engine.blend_motions()

        # Convert to ROS message and publish
        msg = JointCommand()
        msg.header.stamp = self.get_clock().now().to_msg()
        msg.joint_names = list(joint_commands.keys())
        msg.positions = [cmd.position for cmd in joint_commands.values()]
        msg.velocities = [cmd.velocity for cmd in joint_commands.values()]

        self.joint_cmd_pub.publish(msg)
```markdown

## 6. Testing and Validation

### 6.1 Motion Quality Metrics

#### Smoothness Assessment
```python
def calculate_jerk(trajectory):
    """Calculate jerk (third derivative of position) for smoothness evaluation"""
    positions = np.array([frame.position for frame in trajectory])
    velocities = np.gradient(positions, trajectory.dt)
    accelerations = np.gradient(velocities, trajectory.dt)
    jerks = np.gradient(accelerations, trajectory.dt)

    return np.mean(np.abs(jerks))  # Lower is smoother

def smoothness_score(primitive):
    """Score primitive smoothness (0-100, higher is better)"""
    max_jerk = 1000  # Hardware-dependent threshold
    jerk = calculate_jerk(primitive.trajectory)
    return max(0, 100 * (1 - jerk / max_jerk))
```python

#### Emotional Expressiveness
```python
def expressiveness_score(primitive, target_emotion):
    """Evaluate how well primitive conveys target emotion"""
    # Analyze motion characteristics
    amplitude = calculate_motion_amplitude(primitive)
    frequency = calculate_dominant_frequency(primitive)
    symmetry = calculate_motion_symmetry(primitive)

    # Emotion-specific scoring
    if target_emotion == "excitement":
        return score_excitement(amplitude, frequency, symmetry)
    elif target_emotion == "curiosity":
        return score_curiosity(amplitude, frequency, symmetry)
    # ... other emotions
```markdown

### 6.2 Hardware Validation

#### Joint Limit Compliance
```python
def validate_joint_limits(primitive):
    """Ensure all motions stay within hardware constraints"""
    violations = []

    for frame in primitive.trajectory:
        for joint_name, command in frame.items():
            limits = JOINT_LIMITS[joint_name]

            if command.position < limits.min_position:
                violations.append(f"{joint_name} below min: {command.position}")
            if command.position > limits.max_position:
                violations.append(f"{joint_name} above max: {command.position}")
            if abs(command.velocity) > limits.max_velocity:
                violations.append(f"{joint_name} velocity too high: {command.velocity}")

    return violations
```python

#### Performance Benchmarking
```python
def benchmark_primitive_execution():
    """Measure real-world execution performance"""
    test_primitives = [
        "CURIOUS_HEAD_TILT",
        "EXCITEMENT_BOUNCE",
        "SPEAKER_TRACKING",
        "BREATHING_SIMULATION"
    ]

    results = {}

    for primitive_name in test_primitives:
        # Measure execution timing
        start_time = time.time()
        engine.execute_primitive(primitive_name)

        # Wait for completion
        while engine.is_primitive_active(primitive_name):
            time.sleep(0.01)

        execution_time = time.time() - start_time

        # Measure accuracy (compare commanded vs actual positions)
        accuracy = measure_tracking_accuracy(primitive_name)

        results[primitive_name] = {
            "execution_time": execution_time,
            "tracking_accuracy": accuracy,
            "smoothness_score": smoothness_score(primitive_name)
        }

    return results
```

## 7. Future Enhancements

### 7.1 Machine Learning Integration

#### Motion Style Transfer
- Train neural networks to adapt motion primitives to different "personality" styles
- Learn user-specific preferences for motion intensity and timing
- Develop context-aware motion selection based on conversation history

#### Procedural Animation
- Generate new motion primitives through reinforcement learning
- Optimize motion parameters for maximum expressiveness
- Develop adaptive blending weights based on emotional context

### 7.2 Advanced Expression Capabilities

#### Micro-Expression System
- Implement subtle, brief expressions for nuanced emotional communication
- Develop timing-critical expressions synchronized with speech patterns
- Create layered expression system (macro + micro expressions)

#### Environmental Interaction
- Motion primitives that respond to environmental stimuli (wind, vibration, light)
- Adaptive motion based on surface stability and platform dynamics
- Integration with object manipulation capabilities (future arm/hand systems)

This motion primitive catalog provides the foundation for the A2 Robot's expressive capabilities, enabling natural, emotionally coherent interactions while respecting hardware constraints and maintaining system reliability.


===============================================
SENSOR CONFIGURATION GUIDE
===============================================

- --
title: "Sensor Configuration Guide"
type: guide
status: active
created: "2024-01-01"
updated: "2024-01-01"
- --

# A2 Robot: Sensor Configuration & Calibration Guide

> **Document Status:** CURRENT
> **Last Updated:** 2025-05-28
> **Version:** 1.0.0
> **Scope:** Phase 1

> **Status**: CURRENT
> **Last Updated**: 2025-05-27
> **Architecture**: Multi-sensor I2C/Universal Serial Bus (USB) approach (no CSI across gimbal)

## Overview

This guide details the optimal configuration for the A2 Robot's enhanced sensor suite using a robust I2C/Universal Serial Bus (USB) architecture that avoids reliability issues with CSI ribbon cables across gimbal joints.

## Table of Contents

- [Overview](#overview)
- [Architecture Decision: I2C/Universal Serial Bus (USB) Over CSI](#architecture-decision-i2c-usb-over-csi)
  - [Why Multi-Sensor I2C/Universal Serial Bus (USB) Approach](#why-multi-sensor-i2c-usb-approach)
  - [Connection Strategy](#connection-strategy)
- [Depth Camera Configuration](#depth-camera-configuration)
  - [Physical Mounting](#physical-mounting)
  - [Software Configuration](#software-configuration)
  - [Calibration Procedure](#calibration-procedure)
- [Inertial Measurement Unit (IMU) Configuration](#imu-configuration)
  - [I2C Multiplexer Setup (TCA9548A)](#i2c-multiplexer-setup-tca9548a)
  - [Calibration Values Storage](#calibration-values-storage)
- [Power Monitoring Setup](#power-monitoring-setup)
  - [INA219 Configuration](#ina219-configuration)
- [Testing Checklist](#testing-checklist)
  - [I2C Multiplexer Validation](#i2c-multiplexer-validation)
  - [Sensor Connectivity](#sensor-connectivity)
  - [Data Validation](#data-validation)
  - [System Integration](#system-integration)
- [Sensor Integration Timeline](#sensor-integration-timeline)
  - [Week 1-2: Inertial Measurement Unit (IMU) Foundation](#week-1-2-imu-foundation)
  - [Week 3-4: Vision System](#week-3-4-vision-system)
  - [Week 5-6: Near-Field Depth](#week-5-6-near-field-depth)
  - [Week 7-8: Full Integration](#week-7-8-full-integration)
- [Troubleshooting Common Issues](#troubleshooting-common-issues)
  - [I2C Multiplexer Issues](#i2c-multiplexer-issues)
  - [Depth Camera Issues](#depth-camera-issues)
  - [Inertial Measurement Unit (IMU) Calibration Problems](#imu-calibration-problems)
  - [Power Monitoring Accuracy](#power-monitoring-accuracy)
- [Performance Optimization](#performance-optimization)
  - [Data Rates](#data-rates)
  - [CPU Load Distribution](#cpu-load-distribution)
  - [Memory Management](#memory-management)

- --

## Architecture Decision: I2C/Universal Serial Bus (USB) Over CSI

### Why Multi-Sensor I2C/Universal Serial Bus (USB) Approach

- **Problem Solved**: CSI ribbon cables across gimbal joints proved unreliable due to flexing and Electromagnetic Interference (EMI)
- **Solution**: Distributed sensor approach using I2C multiplexer (TCA9548A) and Universal Serial Bus (USB) connections
- **Benefits**:
  - More robust connections through gimbal movement
  - Easier cable management and replacement
  - Better Electromagnetic Interference (EMI) isolation
  - Modular sensor placement

### Connection Strategy

- **RealSense D455**: Universal Serial Bus (USB) 3.0 connection to Raspberry Pi 5
- **Arducam Time-of-Flight (ToF)**: I2C connection via TCA9548A multiplexer
- **Inertial Measurement Unit (IMU) sensors**: I2C via TCA9548A multiplexer
- **VL53L0X sensors**: I2C via TCA9548A multiplexer
- **Power monitoring**: I2C via TCA9548A multiplexer

## Depth Camera Configuration

### Physical Mounting

- **RealSense D455**: Centered at "eye level" of head assembly, Universal Serial Bus (USB) 3.0 cable routed through gimbal with service loop
- **Arducam Time-of-Flight (ToF)**: Mounted 50-75mm directly above Intel RealSense D455, I2C connection via TCA9548A
- **VL53L0X sensors**: Distributed around head perimeter for 360° proximity detection
- **Inertial Measurement Unit (IMU) sensors**: Head Inertial Measurement Unit (IMU) in head assembly, base Inertial Measurement Unit (IMU) in stationary base
- **Cable Management**: All I2C connections use flexible silicone wire, Universal Serial Bus (USB) cable has strain relief
- **Vibration isolation**: TPU dampeners for all camera mounts

### Software Configuration

```yaml

# Multi-sensor configuration for robust perception

sensors:
  realsense_d455:
    connection: usb3
    resolution: [848, 480]  # Balanced for 30fps
    depth_range: [0.4, 9.0]
    filters:
      - temporal
      - spatial
      - decimation: 2

  arducam_tof:
    connection: i2c_mux_channel_2
    resolution: [640, 480]
    fps: 30
    depth_range: [0.2, 2.0]
    integration_time: auto

  vl53l0x_array:
    connection: i2c_mux_channels_3_6
    sensors: 4  # Front, back, left, right
    range: [0.03, 2.0]  # 3cm to 2m
    update_rate: 50  # Hz
    addresses: [0x30, 0x31, 0x32, 0x33]  # Programmed addresses
```python

### Calibration Procedure

1. Capture checkerboard images from both cameras
2. Run stereo calibration between cameras
3. Generate transformation matrix for point cloud fusion
4. Validate with known objects at various distances

## Inertial Measurement Unit (IMU) Configuration

### I2C Multiplexer Setup (TCA9548A)

The TCA9548A TCA9548A I2C multiplexer enables multiple sensors with the same address to coexist on the same I2C bus, critical for our multi-sensor architecture.

```cpp
// TCA9548A I2C Multiplexer Configuration

# define MUX_ADDR 0x70

# define HEAD_IMU_CHANNEL 0

# define BASE_IMU_CHANNEL 1

# define ARDUCAM_TOF_CHANNEL 2

# define VL53L0X_FRONT_CHANNEL 3

# define VL53L0X_BACK_CHANNEL 4

# define VL53L0X_LEFT_CHANNEL 5

# define VL53L0X_RIGHT_CHANNEL 6

# define POWER_MON_CHANNEL 7

void setupMultiplexedSensors() {
    // Initialize IMUs
    selectMuxChannel(HEAD_IMU_CHANNEL);
    headIMU.begin(0x69);  // Head Inertial Measurement Unit (IMU)

    selectMuxChannel(BASE_IMU_CHANNEL);
    baseIMU.begin(0x68);  // Base Inertial Measurement Unit (IMU)

    // Initialize Time-of-Flight (ToF) camera
    selectMuxChannel(ARDUCAM_TOF_CHANNEL);
    arducamToF.begin();

    // Initialize VL53L0X sensors
    selectMuxChannel(VL53L0X_FRONT_CHANNEL);
    frontRangeSensor.begin(0x30);

    selectMuxChannel(VL53L0X_BACK_CHANNEL);
    backRangeSensor.begin(0x31);

    // ... continue for all sensors
}

void selectMuxChannel(uint8_t channel) {
    Wire.beginTransmission(MUX_ADDR);
    Wire.write(1 << channel);
    Wire.endTransmission();
}
```

### Calibration Values Storage

Store magnetometer calibration in EEPROM:
- Hard iron offsets
- Soft iron matrix
- Gyroscope bias
- Accelerometer scale factors

## Power Monitoring Setup

### INA219 Configuration

```python

# Power monitoring assignments

monitors = {
    "main_12v": INA219(0x40),
    "servo_bus": INA219(0x41),
    "pi_5v": INA219(0x42),
    "sensors_5v": INA219(0x43),
    "l16_power": INA219(0x44),
    "system_total": INA219(0x45)
}

# Set calibration for expected current ranges

monitors["main_12v"].set_calibration_32V_8A()
monitors["servo_bus"].set_calibration_16V_5A()
```

## Testing Checklist

### I2C Multiplexer Validation

- [ ] TCA9548A multiplexer responding at 0x70
- [ ] All 8 channels switching correctly
- [ ] No I2C address conflicts detected

### Sensor Connectivity

- [ ] Both IMUs responding on respective I2C channels
- [ ] RealSense D455 detected on Universal Serial Bus (USB) 3.0
- [ ] Arducam Time-of-Flight (ToF) responding via TCA9548A I2C multiplexer
- [ ] All 4 VL53L0X sensors with unique addresses
- [ ] Power monitoring INA219 sensors active

### Data Validation

- [ ] Inertial Measurement Unit (IMU) magnetometer calibration completed
- [ ] Intel RealSense D455 streaming at target framerate (30fps)
- [ ] Arducam Time-of-Flight (ToF) providing depth data (30fps)
- [ ] VL53L0X sensors providing range data (50Hz)
- [ ] Multi-sensor fusion algorithm validated
- [ ] No data dropouts during gimbal movement

### System Integration

- [ ] Audio DOA algorithm functioning
- [ ] Thermal monitoring active
- [ ] Cable strain relief tested through full gimbal range
- [ ] Electromagnetic Interference (EMI) testing passed (no interference between sensors)

## Sensor Integration Timeline

### Week 1-2: Inertial Measurement Unit (IMU) Foundation

**Goal**: Get ICM-20948 IMUs streaming 100Hz data via Teensy 4.1
- Connect head Inertial Measurement Unit (IMU) to Teensy 4.1 I2C
- Implement basic Inertial Measurement Unit (IMU) reading in firmware
- Test data streaming to Raspberry Pi 5 via Universal Asynchronous Receiver-Transmitter (UART)
- Add base Inertial Measurement Unit (IMU) with TCA9548A I2C multiplexer

### Week 3-4: Vision System

**Goal**: RealSense D455 depth streaming
- Connect Intel RealSense D455 to Raspberry Pi 5 Universal Serial Bus (USB) 3.0
- Configure depth streaming at 30fps
- Implement basic obstacle detection
- Test RGB + depth data fusion

### Week 5-6: Near-Field Depth

**Goal**: Arducam Time-of-Flight (ToF) integration
- Mount Time-of-Flight (ToF) camera above Intel RealSense D455
- Configure Time-of-Flight (ToF) streaming
- Implement dual-camera calibration
- Test near-field depth accuracy

### Week 7-8: Full Integration

**Goal**: Complete sensor fusion
- Combine all sensor streams
- Implement sensor fusion algorithms
- Test complete perception pipeline
- Optimize for real-time performance

## Troubleshooting Common Issues

### I2C Multiplexer Issues

- **Multiplexer not detected**: Check TCA9548A power (3.3V) and I2C connections
- **Channel switching fails**: Verify multiplexer address (0x70) and channel selection logic
- **Sensor conflicts**: Use `i2cdetect -y 1` after selecting each channel individually
- **Pull-up resistors**: Use 4.7kΩ on main I2C bus, remove pull-ups on multiplexed channels
- **Cable length**: Keep I2C cable runs under 1 meter, use twisted pair for longer runs

### Depth Camera Issues

- Ensure Universal Serial Bus (USB) 3.0 connection for full bandwidth
- Check power supply capacity for both cameras
- Verify camera mounting alignment

### Inertial Measurement Unit (IMU) Calibration Problems

- Perform calibration in magnetically clean environment
- Store calibration values in non-volatile memory
- Implement automatic bias correction

### Power Monitoring Accuracy

- Verify shunt resistor values
- Calibrate each INA219 for expected current range
- Account for voltage drop in power distribution

## Performance Optimization

### Data Rates

- IMUs: 100Hz (10ms intervals)
- Depth cameras: 30fps synchronized
- Power monitoring: 10Hz
- Audio processing: Real-time with 50ms latency

### CPU Load Distribution

- Teensy 4.1: Inertial Measurement Unit (IMU) processing, safety monitoring
- Raspberry Pi 5 CPU: Sensor fusion, control logic
- Raspberry Pi 5 GPU: Depth processing, computer vision

### Memory Management

- Use circular buffers for sensor data
- Implement zero-copy data transfer where possible
- Monitor memory usage under continuous operation


===============================================
TEENSY FIRMWARE DESIGN
===============================================

- --
title: "Teensy 4.1 Firmware Design"
type: design
status: active
created: "2024-01-01"
updated: "2024-01-01"
- --

# A2 Robot: Teensy 4.1 Firmware Design

## Overview

This document outlines the design architecture and implementation approach.

> **Document Status:** CURRENT
> **Last Updated:** 2025-05-28
> **Version:** 1.0.0
> **Scope:** Phase 1

## Table of Contents

- [Overview](#overview)
- [1. Introduction and Purpose](#1-introduction-and-purpose)
- [2. Hardware Context](#2-hardware-context)
- [3. Firmware Architecture](#3-firmware-architecture)
  - [3.1. RTOS Tasks and Priorities](#3-1-rtos-tasks-and-priorities)
  - [3.2. Inter-Task Communication & Resource Protection](#3-2-inter-task-communication-resource-protection)
- [4. Serial Communication Protocol (Universal Asynchronous Receiver-Transmitter (UART) with Raspberry Pi 5)](#4-serial-communication-protocol-uart-with-raspberry-pi-5)
  - [4.1. Frame Structure](#4-1-frame-structure)
  - [4.2. Message Types (COMMAND_ID examples)](#4-2-message-types-command_id-examples)
    - [4.2.1. Teensy 4.1 to Raspberry Raspberry Pi 5 (Telemetry & Events)](#4-2-1-teensy-to-raspberry-pi-telemetry-events)
    - [4.2.2. Raspberry Raspberry Pi 5 to Teensy 4.1 (Commands & Configuration)](#4-2-2-raspberry-pi-to-teensy-commands-configuration)
  - [4.3. Error Handling & Reliability](#4-3-error-handling-reliability)
  - [4.4. I2C Multiplexer Support](#4-4-i2c-multiplexer-support)
  - [4.5. Current Monitoring Integration](#4-5-current-monitoring-integration)
- [5. Safety Layer (P0) Implementation Details](#5-safety-layer-p0-implementation-details)
- [6. Calibration Data](#6-calibration-data)
- [7. Bootloader and Firmware Updates](#7-bootloader-and-firmware-updates)
- [8. Development and Debugging](#8-development-and-debugging)

- --

## 1. Introduction and Purpose

The Teensy 4.1 microcontroller is a core component of the A2 Robot's onboard system, responsible for ultra-low latency tasks, direct hardware interaction, real-time sensor processing, and acting as the primary safety guardian. This document outlines the architecture, functionalities, and communication protocol of the Teensy 4.1 firmware.

The primary purposes of the Teensy 4.1 firmware are:
-   Implement the **Ultra-Fast Safety Layer (P0)**, capable of immediate hardware intervention.
-   Process feedback from the L16 linear actuators (potentiometer readings).
-   Acquire and perform initial processing/filtering of data from onboard Inertial Measurement Units (IMUs).
-   Manage communication with the Raspberry Pi 5 via a robust serial (Universal Asynchronous Receiver-Transmitter (UART)) protocol.
-   Control any other directly connected low-level sensors or actuators not managed by the Raspberry Raspberry Pi 5.

## 2. Hardware Context

-   **Microcontroller:** Teensy 4.1 (ARM Cortex-M7 @ 600MHz).
-   **Key Peripherals Interfaced:**
    -   6x Actuonix L16-P Linear Actuators: Potentiometer feedback lines connected to Teensy 4.1 analog inputs. *Note: For Stewart platform implementation with 6 actuators, see [Stewart Platform Firmware](stewart-platform-firmware.md)*.
    -   2x SparkFun ICM-20948 IMUs (Head and Base/Torso): Connected via I²C through TCA9548A multiplexer (address 0x70). Head Inertial Measurement Unit (IMU) on channel 0 (0x69), Base Inertial Measurement Unit (IMU) on channel 1 (0x68).
    -   HC-SR04 Ultrasonic Sensor (optional).
    -   Emergency Stop button input.
    -   Communication: Universal Asynchronous Receiver-Transmitter (UART) interface to Raspberry Pi 5.
    -   Output to motor driver enable pins for P0 safety cutoff.

## 3. Firmware Architecture

-   **Operating System:** **FreeRTOS**. The firmware utilizes FreeRTOS for preemptive multitasking, task scheduling, inter-task communication (queues), and resource protection (mutexes), ensuring deterministic behavior for safety-critical operations.
-   **Modularity:** Code is organized into modules for specific functionalities (e.g., `safety_monitor.c`, `actuator_feedback.c`, `imu_handler.c`, `serial_comms.c`).
-   **Interrupt-Driven I/O:** Used for time-critical inputs like the E-Stop button.

### 3.1. RTOS Tasks and Priorities

The firmware implements the following FreeRTOS tasks, with priorities assigned based on criticality (higher number = higher priority):

1.  **`safetyMonitorTask` (Priority: 24 - Highest Real-Time):**
    -   **Period:** 1ms (1000Hz), event-driven for E-Stop.
    -   **Responsibilities:** Monitors E-Stop status, actuator position limits (from shared data), watchdog timeouts from Raspberry Raspberry Pi 5. Implements immediate P0 safety responses (e.g., disabling motor drivers, sending emergency packet).
2.  **`actuatorFeedbackTask` (Priority: 20):**
    -   **Period:** 1ms (1000Hz).
    -   **Responsibilities:** Reads analog values from L16 potentiometers (3 for basic neck, 6 for Stewart platform). Applies calibration and filters readings. Updates a shared telemetry data structure with actuator positions, protected by a mutex (`telemetryDataMutex`). For Stewart platform implementation, also performs inverse kinematics calculations.
3.  **`imuProcessingTask` (Priority: 16):**
    -   **Period:** 5ms (200Hz).
    -   **Responsibilities:** Reads data from Head Inertial Measurement Unit (IMU) and Base Inertial Measurement Unit (IMU). Performs basic calibration offset/scaling. Updates the shared telemetry data structure with processed Inertial Measurement Unit (IMU) values, protected by `telemetryDataMutex`. (Phase 1: Basic processing; full fusion may occur on Raspberry Pi 5).
4.  **`serialCommunicationTask` (Priority: 12):**
    -   **Operation:** Handles all Universal Asynchronous Receiver-Transmitter (UART) communication with the Raspberry Raspberry Pi 5.
    -   **Reception:** Continuously monitors Universal Asynchronous Receiver-Transmitter (UART) RX for incoming packets (non-blocking or using Universal Asynchronous Receiver-Transmitter (UART) RX interrupts/DMA). Parses validated packets.
    -   **Transmission:** Sends packets from a FreeRTOS queue. The primary telemetry packet is sent periodically (e.g., every 10ms / 100Hz). Emergency packets can be sent with higher priority via the queue.
5.  **`heartbeatTask` (Priority: 4 - Lowest):**
    -   **Period:** 100ms (10Hz).
    -   **Responsibilities:** Toggles an onboard LED for visual indication of firmware operation. May periodically queue a firmware version or basic status packet for transmission via `serialCommunicationTask`.

### 3.2. Inter-Task Communication & Resource Protection

-   **Telemetry Data:** A shared data structure (e.g., a C struct) holds the latest sensor readings (L16 positions, Inertial Measurement Unit (IMU) data) and system status. Access to this structure by `actuatorFeedbackTask`, `imuProcessingTask`, and `serialCommunicationTask` (for populating outgoing telemetry packets) is protected by a FreeRTOS mutex (e.g., `telemetryDataMutex`) to prevent race conditions.
-   **Outgoing Universal Asynchronous Receiver-Transmitter (UART) Packets:** Tasks like `safetyMonitorTask` (for emergency packets) and `heartbeatTask` (for status packets), and `serialCommunicationTask` itself (for regular telemetry) will send data by placing formatted packet structures onto a FreeRTOS queue (e.g., `uartTxQueue`). The `serialCommunicationTask` dequeues these and handles the actual Universal Asynchronous Receiver-Transmitter (UART) transmission. This decouples packet generation from transmission.

## 4. Serial Communication Protocol (Universal Asynchronous Receiver-Transmitter (UART) with Raspberry Pi 5)

A robust, packetized serial protocol is used.

### 4.1. Frame Structure

`[START_BYTE_0] [START_BYTE_1] [LENGTH] [COMMAND_ID] [PAYLOAD...] [CHECKSUM_0] [CHECKSUM_1]`
-   **`START_BYTE_0` / `START_BYTE_1`:** `0xAA`, `0x55`.
-   **`LENGTH`:** Number of bytes in `PAYLOAD`. (uint8_t)
-   **`COMMAND_ID`:** Byte identifying the type of message. (uint8_t)
-   **`PAYLOAD`:** Data bytes, specific to `COMMAND_ID`. Little Endian.
-   **`CHECKSUM_0` / `CHECKSUM_1`:** 16-bit CRC16-CCITT of `LENGTH`, `COMMAND_ID`, and `PAYLOAD`.

### 4.2. Message Types (COMMAND_ID examples)

#### 4.2.1. Teensy 4.1 to Raspberry Raspberry Pi 5 (Telemetry & Events)
-   **`CMD_TEENSY_TELEMETRY_PACKET (0x01)`:**
    -   Payload: L16 Positions (float array, 3 or 6 values), Head Inertial Measurement Unit (IMU) (Acc/Gyr/Mag or Quat), Base Inertial Measurement Unit (IMU) (Acc/Gyr/Mag or Quat), Safety Status Bits (uint8_t), Timestamp (uint32_t ms). For Stewart platform: includes platform pose (x,y,z,roll,pitch,yaw).
    -   Sent periodically by `serialCommunicationTask` (e.g., 100Hz).
-   **`CMD_P0_EMERGENCY_EVENT (0x02)`:**
    -   Payload: Event code (uint8_t: `E_STOP_ACTIVATED`, `MOTOR_A_OVERCURRENT`, etc.).
    -   Queued immediately by `safetyMonitorTask`.
-   **`CMD_ACKNOWLEDGE (0x03)`:**
    -   Payload: `COMMAND_ID` of Raspberry Pi 5 message being acknowledged.
-   **`CMD_TEENSY_FIRMWARE_VERSION (0x04)`:**
    -   Payload: Version string (e.g., "A2_TEENSY_FW_1.1.0_RTOS").
    -   Sent by `heartbeatTask` periodically or in response to `CMD_PI_REQUEST_FW_VERSION`.

#### 4.2.2. Raspberry Raspberry Pi 5 to Teensy 4.1 (Commands & Configuration)
-   **`CMD_PI_SET_SAFETY_PARAMS (0x80)`:** Payload: Safety thresholds.
-   **`CMD_PI_WATCHDOG_PING (0x81)`:** Payload: Optional sequence number. Processed by `safetyMonitorTask`.
-   **`CMD_PI_REQUEST_FW_VERSION (0x82)`:** Payload: None.
-   **`CMD_PI_RESET_TEENSY (0x83)`:** Payload: None. (Use with extreme caution).
-   **`CMD_PI_SET_MOTOR_ENABLES (0x84)`:** Payload: Bitmask for P0 motor driver enables.
-   **`CMD_PI_ACKNOWLEDGE_P0_EVENT (0x85)`:** Payload: `P0_EVENT_CODE` being acknowledged. Allows Raspberry Pi 5 to confirm receipt of critical event.

### 4.3. Error Handling & Reliability

-   CRC16 validation for all received packets. Invalid packets are discarded.
-   Robust start-byte detection and length checking for packet framing.
-   Watchdog timer in `safetyMonitorTask` expects periodic `CMD_PI_WATCHDOG_PING` from Raspberry Pi 5. Failure to receive pings triggers a safety state (e.g., P0 motor disable).

### 4.4. I2C Multiplexer Support

The Teensy 4.1 manages dual IMUs through TCA9548A:

```cpp
// I2C Multiplexer control

# define TCAADDR 0x70

void tcaselect(uint8_t channel) {
  Wire.beginTransmission(TCAADDR);
  Wire.write(1 << channel);
  Wire.endTransmission();
}

// Inertial Measurement Unit (IMU) Reading Task
void imuProcessingTaskFunc(void* parameters) {
  while(1) {
    // Read Head Inertial Measurement Unit (IMU)
    tcaselect(0);
    headIMU.readSensor();

    // Read Base Inertial Measurement Unit (IMU)
    tcaselect(1);
    baseIMU.readSensor();

    // Package and send via Universal Asynchronous Receiver-Transmitter (UART)
    sendIMUPacket(headIMU, baseIMU);

    vTaskDelayUntil(&xLastWakeTime, pdMS_TO_TICKS(10)); // 100Hz
  }
}
```

### 4.5. Current Monitoring Integration

Add INA219 support for power telemetry:

```cpp
// Power monitoring addresses

# define INA_MAIN    0x40

# define INA_SERVOS  0x41

# define INA_PI      0x42

# define INA_SENSORS 0x43

# define INA_L16     0x44

struct PowerTelemetry {
  float mainCurrent;
  float servoCurrent;
  float piCurrent;
  float sensorCurrent;
  float l16Current;
  float totalPower;
};
```

## 5. Safety Layer (P0) Implementation Details

-   **E-Stop:** Monitored by `safetyMonitorTask` via direct interrupt or frequent polling.
-   **Motor Current Monitoring:** If feasible via Teensy 4.1 ADCs from BTS7960 sense lines, monitored by `safetyMonitorTask`.
-   **Inertial Measurement Unit (IMU)-Based Fall/Tilt Detection:** `safetyMonitorTask` uses processed Inertial Measurement Unit (IMU) data.
-   **Actuator Position Limits:** `safetyMonitorTask` checks L16 positions against configured software limits.
-   **Response:** All P0 events trigger immediate disabling of motor driver enable lines (via direct Teensy 4.1 GPIOs) and queuing of `CMD_P0_EMERGENCY_EVENT` packet.

## 6. Calibration Data

-   Inertial Measurement Unit (IMU) calibration (offsets/scales) and L16 actuator ADC range parameters stored in Teensy 4.1's EEPROM.
-   Loaded at boot by relevant tasks.
-   Mechanism for updating calibration via Universal Asynchronous Receiver-Transmitter (UART) commands from Raspberry Pi 5 (e.g., `CMD_PI_SET_CALIBRATION_DATA (0x90)` - not yet in list but good to consider).

## 7. Bootloader and Firmware Updates

-   Standard Teensy 4.1 HalfKay bootloader via Universal Serial Bus (USB).
-   `platformio.ini` must correctly specify the Teensy 4.1 board and any FreeRTOS library dependencies (e.g., `lib_deps = featherfly/FreeRTOS@^10.5.1-1`).

## 8. Development and Debugging

-   PlatformIO as the development environment.
-   Dedicated debug Universal Asynchronous Receiver-Transmitter (UART) (e.g., `Serial1`) for `printf`-style debugging, separate from main Raspberry Pi 5 comms Universal Asynchronous Receiver-Transmitter (UART).
-   Onboard LED for heartbeat and error codes.
-   FreeRTOS task analysis tools (if available via debugger/plugins) for stack usage, CPU time.

This firmware design, now explicitly incorporating FreeRTOS, provides a deterministic, safe, and communicative foundation for the A2 robot's low-level operations, ready for robust interaction with the Raspberry Raspberry Pi 5 Hardware Interface Layer (HIL).
